{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6420761",
   "metadata": {},
   "source": [
    "# Advanced Preprocessing Pipelines\n",
    "\n",
    "This notebook demonstrates the sophisticated preprocessing capabilities of the sklearn-mastery project, including custom transformers, intelligent preprocessing strategies, and pipeline construction patterns with comprehensive results saving and analysis.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Results Management System](#results)\n",
    "3. [Custom Transformers](#custom-transformers)\n",
    "4. [Intelligent Data Preprocessing](#intelligent-preprocessing)\n",
    "5. [Pipeline Factory Patterns](#pipeline-factory)\n",
    "6. [Data Validation and Quality](#data-validation)\n",
    "7. [Advanced Pipeline Techniques](#advanced-techniques)\n",
    "8. [Performance Comparison](#performance-comparison)\n",
    "9. [Comprehensive Results Saving](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bce3b6",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports {#setup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a112fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, r2_score, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Additional imports for advanced techniques\n",
    "import time\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Results management imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import datetime\n",
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5423cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project imports\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data.generators import SyntheticDataGenerator\n",
    "from data.preprocessors import DataPreprocessor, CategoricalEncoder, NumericalTransformer\n",
    "from data.validators import DataValidator, ValidationSeverity\n",
    "from pipelines.custom_transformers import *\n",
    "from pipelines.pipeline_factory import PipelineFactory\n",
    "from evaluation.metrics import ModelEvaluator\n",
    "from evaluation.visualization import ModelVisualizationSuite\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd2e20d",
   "metadata": {},
   "source": [
    "## 2. Results Management System {#results}\n",
    "\n",
    "Comprehensive results management system for saving preprocessing pipelines, figures, and analysis reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3956496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Results Management System for Preprocessing\n",
    "def setup_results_directories():\n",
    "    \"\"\"Create comprehensive results directory structure for preprocessing.\"\"\"\n",
    "    base_dir = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "    results_dir = base_dir / 'results'\n",
    "    \n",
    "    # Create comprehensive subdirectories\n",
    "    directories = [\n",
    "        'figures', 'models', 'reports', 'experiments',\n",
    "        'pipelines', 'transformers', 'preprocessing_analysis'\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        (results_dir / directory).mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"üìÅ Created/verified: {results_dir / directory}\")\n",
    "    \n",
    "    return results_dir\n",
    "\n",
    "def get_timestamp():\n",
    "    \"\"\"Get formatted timestamp for file naming.\"\"\"\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "def save_preprocessing_figure(fig, name, description=\"\", dpi=300):\n",
    "    \"\"\"Save preprocessing figure with proper naming and metadata.\"\"\"\n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{timestamp}_preprocessing_{name}.png\"\n",
    "    filepath = results_dir / 'figures' / filename\n",
    "    \n",
    "    # Save figure\n",
    "    fig.savefig(filepath, dpi=dpi, bbox_inches='tight', facecolor='white')\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'filename': filename,\n",
    "        'description': description,\n",
    "        'timestamp': timestamp,\n",
    "        'notebook': '02_preprocessing_pipelines',\n",
    "        'category': 'preprocessing',\n",
    "        'dpi': dpi,\n",
    "        'figure_size': fig.get_size_inches().tolist()\n",
    "    }\n",
    "    \n",
    "    metadata_file = results_dir / 'figures' / f\"{timestamp}_preprocessing_{name}_metadata.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"üíæ Preprocessing figure saved: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_preprocessing_pipeline(pipeline, name, description=\"\", metadata=None):\n",
    "    \"\"\"Save preprocessing pipeline with proper naming and metadata.\"\"\"\n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{timestamp}_pipeline_{name}.joblib\"\n",
    "    filepath = results_dir / 'pipelines' / filename\n",
    "    \n",
    "    # Save pipeline\n",
    "    joblib.dump(pipeline, filepath, compress=3)\n",
    "    \n",
    "    # Save metadata\n",
    "    pipeline_metadata = {\n",
    "        'filename': filename,\n",
    "        'pipeline_name': name,\n",
    "        'description': description,\n",
    "        'timestamp': timestamp,\n",
    "        'notebook': '02_preprocessing_pipelines',\n",
    "        'pipeline_type': pipeline.__class__.__name__ if hasattr(pipeline, '__class__') else str(type(pipeline)),\n",
    "        'steps': [step[0] for step in pipeline.steps] if hasattr(pipeline, 'steps') else [],\n",
    "        'file_size_mb': filepath.stat().st_size / (1024*1024) if filepath.exists() else 0\n",
    "    }\n",
    "    \n",
    "    if metadata:\n",
    "        pipeline_metadata.update(metadata)\n",
    "    \n",
    "    metadata_file = results_dir / 'pipelines' / f\"{timestamp}_pipeline_{name}_metadata.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(pipeline_metadata, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Pipeline saved: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_custom_transformer(transformer, name, description=\"\", metadata=None):\n",
    "    \"\"\"Save custom transformer with proper naming and metadata.\"\"\"\n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{timestamp}_transformer_{name}.joblib\"\n",
    "    filepath = results_dir / 'transformers' / filename\n",
    "    \n",
    "    # Save transformer\n",
    "    joblib.dump(transformer, filepath, compress=3)\n",
    "    \n",
    "    # Save metadata\n",
    "    transformer_metadata = {\n",
    "        'filename': filename,\n",
    "        'transformer_name': name,\n",
    "        'description': description,\n",
    "        'timestamp': timestamp,\n",
    "        'notebook': '02_preprocessing_pipelines',\n",
    "        'transformer_type': transformer.__class__.__name__,\n",
    "        'category': 'custom_transformer',\n",
    "        'file_size_mb': filepath.stat().st_size / (1024*1024) if filepath.exists() else 0\n",
    "    }\n",
    "    \n",
    "    if metadata:\n",
    "        transformer_metadata.update(metadata)\n",
    "    \n",
    "    metadata_file = results_dir / 'transformers' / f\"{timestamp}_transformer_{name}_metadata.json\"\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(transformer_metadata, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Transformer saved: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_experiment_results(experiment_name, results, description=\"\", category=\"general\"):\n",
    "    \"\"\"Save experiment results with detailed configuration.\"\"\"\n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{timestamp}_preprocessing_{category}_{experiment_name}.json\"\n",
    "    filepath = results_dir / 'experiments' / filename\n",
    "    \n",
    "    experiment_data = {\n",
    "        'experiment_name': experiment_name,\n",
    "        'description': description,\n",
    "        'category': category,\n",
    "        'timestamp': timestamp,\n",
    "        'notebook': '02_preprocessing_pipelines',\n",
    "        'results': results,\n",
    "        'system_info': {\n",
    "            'python_version': sys.version,\n",
    "            'numpy_version': np.__version__,\n",
    "            'pandas_version': pd.__version__\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(experiment_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Experiment results saved: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def save_report(content, name, description=\"\", category=\"general\", format='txt'):\n",
    "    \"\"\"Save comprehensive analysis report.\"\"\"\n",
    "    timestamp = get_timestamp()\n",
    "    filename = f\"{timestamp}_preprocessing_{category}_{name}.{format}\"\n",
    "    filepath = results_dir / 'reports' / filename\n",
    "    \n",
    "    if format == 'txt':\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(content)\n",
    "    elif format == 'json':\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(content, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üíæ Report saved: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# Initialize results directories\n",
    "results_dir = setup_results_directories()\n",
    "print(f\"\\nüìä Preprocessing results will be saved to: {results_dir}\")\n",
    "print(\"üîß Results management system initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5cbe3",
   "metadata": {},
   "source": [
    "## 3. Custom Transformers {#custom-transformers}\n",
    "\n",
    "Let's explore the custom transformers that extend sklearn's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04697cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data for preprocessing demonstrations\n",
    "print(\"üéØ Generating Sample Data for Preprocessing Demonstrations...\")\n",
    "\n",
    "generator = SyntheticDataGenerator(random_state=42)\n",
    "\n",
    "# Mixed data types dataset\n",
    "X_mixed, y_mixed = generator.mixed_data_types(\n",
    "    n_samples=1000,\n",
    "    n_numerical=8,\n",
    "    n_categorical=4,\n",
    "    n_ordinal=2\n",
    ")\n",
    "\n",
    "print(f\"üìä Generated mixed dataset: {X_mixed.shape}\")\n",
    "print(f\"Data types: {X_mixed.dtypes.value_counts().to_dict()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(X_mixed.head().to_string())\n",
    "\n",
    "print(\"\\n‚ú® Sample data generated successfully!\")\n",
    "\n",
    "# Save sample dataset for reference\n",
    "sample_dataset_metadata = {\n",
    "    'shape': X_mixed.shape,\n",
    "    'data_types': X_mixed.dtypes.to_dict(),\n",
    "    'target_classes': len(np.unique(y_mixed)),\n",
    "    'description': 'Mixed data types demonstration dataset'\n",
    "}\n",
    "\n",
    "save_experiment_results('sample_mixed_dataset', sample_dataset_metadata,\n",
    "                       'Generated sample dataset for preprocessing demonstrations', 'data_generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f102f9cc",
   "metadata": {},
   "source": [
    "### 3.1 Outlier Removal Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a093b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate OutlierRemover transformer\n",
    "print(\"üîç Testing OutlierRemover with Different Methods...\")\n",
    "\n",
    "# Create data with obvious outliers\n",
    "np.random.seed(42)\n",
    "X_outliers = np.random.randn(200, 4)\n",
    "# Add some extreme outliers\n",
    "X_outliers[::50] += np.random.randn(4, 4) * 5  # Every 50th sample becomes an outlier\n",
    "\n",
    "methods = ['isolation_forest', 'lof', 'z_score']\n",
    "outlier_results = {}\n",
    "\n",
    "print(\"\\n--- Outlier Detection Results ---\")\n",
    "for method in methods:\n",
    "    outlier_remover = OutlierRemover(method=method, contamination=0.1)\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_clean = outlier_remover.fit_transform(X_outliers)\n",
    "    \n",
    "    outliers_detected = len(X_outliers) - len(X_clean)\n",
    "    outlier_results[method] = {\n",
    "        'original_samples': len(X_outliers),\n",
    "        'clean_samples': len(X_clean),\n",
    "        'outliers_detected': outliers_detected,\n",
    "        'outlier_percentage': (outliers_detected / len(X_outliers)) * 100\n",
    "    }\n",
    "    \n",
    "    print(f\"  {method}: {outliers_detected} outliers detected ({outlier_results[method]['outlier_percentage']:.1f}%)\")\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Original data\n",
    "axes[0].scatter(X_outliers[:, 0], X_outliers[:, 1], alpha=0.6, c='blue')\n",
    "axes[0].set_title('Original Data (with outliers)', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Results for each method\n",
    "colors = ['green', 'orange', 'purple']\n",
    "for i, method in enumerate(methods):\n",
    "    outlier_remover = OutlierRemover(method=method, contamination=0.1)\n",
    "    X_clean = outlier_remover.fit_transform(X_outliers)\n",
    "    \n",
    "    axes[i+1].scatter(X_clean[:, 0], X_clean[:, 1], alpha=0.6, c=colors[i])\n",
    "    axes[i+1].set_title(f'After {method.replace(\"_\", \" \").title()} Removal', \n",
    "                       fontsize=12, fontweight='bold')\n",
    "    axes[i+1].set_xlabel('Feature 1')\n",
    "    axes[i+1].set_ylabel('Feature 2')\n",
    "    axes[i+1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save outlier removal visualization\n",
    "save_preprocessing_figure(fig, 'outlier_removal_comparison', \n",
    "                         'Comparison of different outlier removal methods')\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(\"\\nüìä Outlier Detection Summary:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Method':<20} {'Original':<10} {'Clean':<10} {'Removed':<10} {'Percentage':<10}\")\n",
    "print(\"=\" * 70)\n",
    "for method, data in outlier_results.items():\n",
    "    print(f\"{method:<20} {data['original_samples']:<10} {data['clean_samples']:<10} \"\n",
    "          f\"{data['outliers_detected']:<10} {data['outlier_percentage']:<10.1f}%\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save outlier removal transformers and results\n",
    "for method in methods:\n",
    "    outlier_transformer = OutlierRemover(method=method, contamination=0.1)\n",
    "    save_custom_transformer(outlier_transformer, f\"outlier_remover_{method}\",\n",
    "                           f\"Outlier removal transformer using {method} method\",\n",
    "                           {'method': method, 'contamination': 0.1})\n",
    "\n",
    "save_experiment_results('outlier_removal_comparison', outlier_results,\n",
    "                       'Comparison of outlier removal methods performance', 'outlier_detection')\n",
    "\n",
    "print(\"\\n‚ú® OutlierRemover successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5848d92",
   "metadata": {},
   "source": [
    "### 3.2 Feature Interaction Creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate FeatureInteractionCreator\n",
    "print(\"üîß Testing FeatureInteractionCreator...\")\n",
    "\n",
    "# Create simple dataset for demonstration\n",
    "np.random.seed(42)\n",
    "X_simple = np.random.randn(300, 5)\n",
    "y_simple = (X_simple[:, 0] * X_simple[:, 1] + \n",
    "           X_simple[:, 2] ** 2 + \n",
    "           np.random.randn(300) * 0.1)\n",
    "\n",
    "print(f\"Original features: {X_simple.shape[1]}\")\n",
    "\n",
    "# Test different configurations\n",
    "configs = [\n",
    "    {'degree': 2, 'interaction_only': True, 'max_features': 15, 'name': 'Interactions Only'},\n",
    "    {'degree': 2, 'interaction_only': False, 'max_features': 20, 'name': 'Polynomial Features'},\n",
    "    {'degree': 3, 'interaction_only': True, 'max_features': 25, 'name': 'Cubic Interactions'}\n",
    "]\n",
    "\n",
    "transformation_results = []\n",
    "\n",
    "print(\"\\n--- Feature Transformation Results ---\")\n",
    "for i, config in enumerate(configs):\n",
    "    feature_creator = FeatureInteractionCreator(\n",
    "        degree=config['degree'], \n",
    "        interaction_only=config['interaction_only'], \n",
    "        max_features=config['max_features']\n",
    "    )\n",
    "    X_transformed = feature_creator.fit_transform(X_simple, y_simple)\n",
    "    \n",
    "    result = {\n",
    "        'name': config['name'],\n",
    "        'original_features': X_simple.shape[1],\n",
    "        'new_features': X_transformed.shape[1],\n",
    "        'expansion_ratio': X_transformed.shape[1] / X_simple.shape[1]\n",
    "    }\n",
    "    transformation_results.append(result)\n",
    "    \n",
    "    print(f\"  {config['name']}: {X_simple.shape[1]} ‚Üí {X_transformed.shape[1]} features \"\n",
    "          f\"(ratio: {result['expansion_ratio']:.1f}x)\")\n",
    "\n",
    "# Compare model performance with and without feature interactions\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_simple, y_simple, test_size=0.3, random_state=42)\n",
    "\n",
    "performance_results = {}\n",
    "\n",
    "# Without interactions\n",
    "model_simple = LinearRegression()\n",
    "model_simple.fit(X_train, y_train)\n",
    "y_pred_simple = model_simple.predict(X_test)\n",
    "mse_simple = mean_squared_error(y_test, y_pred_simple)\n",
    "r2_simple = model_simple.score(X_test, y_test)\n",
    "\n",
    "performance_results['Original'] = {\n",
    "    'mse': mse_simple,\n",
    "    'r2': r2_simple,\n",
    "    'features': X_simple.shape[1]\n",
    "}\n",
    "\n",
    "# With interactions\n",
    "feature_creator = FeatureInteractionCreator(degree=2, interaction_only=True, max_features=15)\n",
    "X_train_inter = feature_creator.fit_transform(X_train, y_train)\n",
    "X_test_inter = feature_creator.transform(X_test)\n",
    "\n",
    "model_inter = LinearRegression()\n",
    "model_inter.fit(X_train_inter, y_train)\n",
    "y_pred_inter = model_inter.predict(X_test_inter)\n",
    "mse_inter = mean_squared_error(y_test, y_pred_inter)\n",
    "r2_inter = model_inter.score(X_test_inter, y_test)\n",
    "\n",
    "performance_results['With Interactions'] = {\n",
    "    'mse': mse_inter,\n",
    "    'r2': r2_inter,\n",
    "    'features': X_train_inter.shape[1]\n",
    "}\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Feature expansion visualization\n",
    "config_names = [r['name'] for r in transformation_results]\n",
    "feature_counts = [r['new_features'] for r in transformation_results]\n",
    "\n",
    "bars1 = axes[0].bar(config_names, feature_counts, color=['lightblue', 'lightcoral', 'lightgreen'], alpha=0.7)\n",
    "axes[0].set_title('Feature Count After Transformation', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of Features')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, count in zip(bars1, feature_counts):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Performance comparison\n",
    "model_names = list(performance_results.keys())\n",
    "r2_scores = [performance_results[name]['r2'] for name in model_names]\n",
    "mse_scores = [performance_results[name]['mse'] for name in model_names]\n",
    "\n",
    "bars2 = axes[1].bar(model_names, r2_scores, color=['skyblue', 'orange'], alpha=0.7)\n",
    "axes[1].set_title('Model Performance Comparison', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('R¬≤ Score')\n",
    "axes[1].set_ylim(0, 1)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, r2 in zip(bars2, r2_scores):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                f'{r2:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save feature interaction analysis\n",
    "save_preprocessing_figure(fig, 'feature_interaction_analysis', \n",
    "                         'Analysis of feature interaction creation methods')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìà Performance Comparison:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<20} {'R¬≤ Score':<10} {'MSE':<10} {'Features':<10}\")\n",
    "print(\"=\" * 60)\n",
    "for name, results in performance_results.items():\n",
    "    print(f\"{name:<20} {results['r2']:<10.3f} {results['mse']:<10.3f} {results['features']:<10}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "improvement = ((r2_inter - r2_simple) / r2_simple * 100) if r2_simple != 0 else 0\n",
    "print(f\"\\nüéØ Key Insights:\")\n",
    "print(f\"  ‚Ä¢ R¬≤ improvement with interactions: {improvement:.1f}%\")\n",
    "print(f\"  ‚Ä¢ MSE reduction: {((mse_simple - mse_inter) / mse_simple * 100):.1f}%\")\n",
    "print(f\"  ‚Ä¢ Feature expansion: {X_simple.shape[1]} ‚Üí {X_train_inter.shape[1]} features\")\n",
    "\n",
    "# Save feature interaction creators and results\n",
    "for config in configs:\n",
    "    feature_transformer = FeatureInteractionCreator(\n",
    "        degree=config['degree'], \n",
    "        interaction_only=config['interaction_only'], \n",
    "        max_features=config['max_features']\n",
    "    )\n",
    "    save_custom_transformer(feature_transformer, f\"feature_creator_{config['name'].lower().replace(' ', '_')}\",\n",
    "                           f\"Feature interaction creator: {config['name']}\", config)\n",
    "\n",
    "save_experiment_results('feature_interaction_analysis', {\n",
    "    'transformation_results': transformation_results,\n",
    "    'performance_results': performance_results,\n",
    "    'improvement_percentage': improvement\n",
    "}, 'Analysis of feature interaction creation methods', 'feature_engineering')\n",
    "\n",
    "print(\"\\n‚ú® FeatureInteractionCreator successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e1691",
   "metadata": {},
   "source": [
    "### 3.3 Domain-Specific Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458f19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate DomainSpecificEncoder\n",
    "print(\"üè∑Ô∏è Testing DomainSpecificEncoder...\")\n",
    "\n",
    "# Create categorical data with different cardinalities\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "data = {\n",
    "    'low_cardinality': np.random.choice(['A', 'B', 'C'], n_samples),\n",
    "    'medium_cardinality': np.random.choice([f'Cat_{i}' for i in range(10)], n_samples),\n",
    "    'high_cardinality': np.random.choice([f'ID_{i}' for i in range(100)], n_samples),\n",
    "    'numerical': np.random.randn(n_samples)\n",
    "}\n",
    "\n",
    "df_categorical = pd.DataFrame(data)\n",
    "y_categorical = np.random.randint(0, 2, n_samples)\n",
    "\n",
    "print(f\"Dataset shape: {df_categorical.shape}\")\n",
    "print(f\"Cardinalities: {df_categorical.nunique().to_dict()}\")\n",
    "\n",
    "# Test different encoding strategies\n",
    "strategies = ['auto', 'onehot', 'target']\n",
    "encoding_results = {}\n",
    "\n",
    "print(\"\\n--- Encoding Strategy Results ---\")\n",
    "for strategy in strategies:\n",
    "    encoder = DomainSpecificEncoder(\n",
    "        categorical_strategy=strategy,\n",
    "        max_cardinality=20\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        X_encoded = encoder.fit_transform(df_categorical, y_categorical)\n",
    "        \n",
    "        encoding_results[strategy] = {\n",
    "            'original_features': df_categorical.shape[1],\n",
    "            'encoded_features': X_encoded.shape[1],\n",
    "            'expansion_ratio': X_encoded.shape[1] / df_categorical.shape[1],\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        print(f\"  {strategy.upper()}: {df_categorical.shape[1]} ‚Üí {X_encoded.shape[1]} features \"\n",
    "              f\"(ratio: {encoding_results[strategy]['expansion_ratio']:.1f}x)\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        encoding_results[strategy] = {'success': False, 'error': str(e)}\n",
    "        print(f\"  {strategy.upper()}: ‚ùå Failed - {str(e)}\")\n",
    "\n",
    "# Visualize encoding strategies\n",
    "successful_strategies = [s for s in encoding_results if encoding_results[s].get('success', False)]\n",
    "feature_counts = [encoding_results[s]['encoded_features'] for s in successful_strategies]\n",
    "\n",
    "if successful_strategies:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Feature count comparison\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(successful_strategies)))\n",
    "    bars = axes[0].bar(successful_strategies, feature_counts, color=colors, alpha=0.7)\n",
    "    axes[0].set_title('Feature Count After Encoding by Strategy', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Encoding Strategy')\n",
    "    axes[0].set_ylabel('Number of Features')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, count in zip(bars, feature_counts):\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, \n",
    "                    str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Expansion ratio comparison\n",
    "    expansion_ratios = [encoding_results[s]['expansion_ratio'] for s in successful_strategies]\n",
    "    bars2 = axes[1].bar(successful_strategies, expansion_ratios, color=colors, alpha=0.7)\n",
    "    axes[1].set_title('Feature Expansion Ratio by Strategy', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Encoding Strategy')\n",
    "    axes[1].set_ylabel('Expansion Ratio')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, ratio in zip(bars2, expansion_ratios):\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                    f'{ratio:.1f}x', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save encoding strategy comparison\n",
    "    save_preprocessing_figure(fig, 'encoding_strategy_comparison', \n",
    "                             'Comparison of categorical encoding strategies')\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\nüìä Encoding Strategy Summary:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"{'Strategy':<15} {'Original':<10} {'Encoded':<10} {'Ratio':<10} {'Status':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "    for strategy in strategies:\n",
    "        if encoding_results[strategy].get('success', False):\n",
    "            r = encoding_results[strategy]\n",
    "            print(f\"{strategy.upper():<15} {r['original_features']:<10} {r['encoded_features']:<10} \"\n",
    "                  f\"{r['expansion_ratio']:<10.1f} {'Success':<15}\")\n",
    "        else:\n",
    "            print(f\"{strategy.upper():<15} {'N/A':<10} {'N/A':<10} {'N/A':<10} {'Failed':<15}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "# Save domain-specific encoders and results\n",
    "for strategy in strategies:\n",
    "    domain_encoder = DomainSpecificEncoder(\n",
    "        categorical_strategy=strategy,\n",
    "        max_cardinality=20\n",
    "    )\n",
    "    save_custom_transformer(domain_encoder, f\"domain_encoder_{strategy}\",\n",
    "                           f\"Domain-specific encoder with {strategy} strategy\",\n",
    "                           {'strategy': strategy, 'max_cardinality': 20})\n",
    "\n",
    "save_experiment_results('encoding_strategy_comparison', encoding_results,\n",
    "                       'Comparison of categorical encoding strategies', 'encoding')\n",
    "\n",
    "print(\"\\n‚ú® DomainSpecificEncoder successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8912d6",
   "metadata": {},
   "source": [
    "## 4. Intelligent Data Preprocessing {#intelligent-preprocessing}\n",
    "\n",
    "The DataPreprocessor automatically adapts preprocessing strategies based on data characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23adb521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate intelligent preprocessing\n",
    "print(\"üß† Testing Intelligent DataPreprocessor...\")\n",
    "\n",
    "# Create dataset with various data quality issues\n",
    "np.random.seed(42)\n",
    "n_samples = 800\n",
    "\n",
    "# Generate base data with realistic issues\n",
    "data_with_issues = {\n",
    "    'normal_feature': np.random.randn(n_samples),\n",
    "    'skewed_feature': np.random.exponential(2, n_samples),\n",
    "    'feature_with_outliers': np.concatenate([\n",
    "        np.random.randn(n_samples - 20),\n",
    "        np.random.randn(20) * 10  # Outliers\n",
    "    ]),\n",
    "    'categorical_low': np.random.choice(['A', 'B', 'C'], n_samples),\n",
    "    'categorical_high': np.random.choice([f'Cat_{i}' for i in range(50)], n_samples),\n",
    "    'constant_feature': np.full(n_samples, 42),  # Constant feature\n",
    "    'nearly_constant': np.random.choice([1, 2], n_samples, p=[0.95, 0.05])  # Nearly constant\n",
    "}\n",
    "\n",
    "# Add missing values strategically\n",
    "missing_indices = np.random.choice(n_samples, size=int(0.1 * n_samples), replace=False)\n",
    "data_with_issues['normal_feature'] = np.array(data_with_issues['normal_feature'], dtype=float)\n",
    "data_with_issues['normal_feature'][missing_indices] = np.nan\n",
    "\n",
    "df_issues = pd.DataFrame(data_with_issues)\n",
    "y_issues = np.random.randint(0, 2, n_samples)\n",
    "\n",
    "print(f\"Dataset with issues shape: {df_issues.shape}\")\n",
    "print(f\"Missing values per column: {df_issues.isnull().sum().to_dict()}\")\n",
    "print(f\"Data types: {df_issues.dtypes.to_dict()}\")\n",
    "\n",
    "# Initialize intelligent preprocessor\n",
    "preprocessor = DataPreprocessor(\n",
    "    handle_missing=True,\n",
    "    handle_outliers=True,\n",
    "    normalize_features=True,\n",
    "    encode_categoricals=True,\n",
    "    feature_selection=True\n",
    ")\n",
    "\n",
    "# Analyze data before preprocessing\n",
    "print(\"\\nüìä Data Analysis Before Preprocessing:\")\n",
    "analysis = preprocessor.analyze_data(df_issues)\n",
    "print(\"=\" * 50)\n",
    "for key, value in analysis.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Fit and transform\n",
    "X_processed = preprocessor.fit_transform(df_issues, y_issues)\n",
    "\n",
    "print(f\"\\n‚ú® Preprocessing Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Original shape: {df_issues.shape}\")\n",
    "print(f\"  Processed shape: {X_processed.shape}\")\n",
    "print(f\"  Features reduced by: {((df_issues.shape[1] - X_processed.shape[1]) / df_issues.shape[1] * 100):.1f}%\")\n",
    "print(f\"  Samples retained: {(X_processed.shape[0] / df_issues.shape[0] * 100):.1f}%\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show preprocessing steps applied\n",
    "steps_applied = preprocessor.get_applied_steps()\n",
    "print(f\"\\nüîß Preprocessing Steps Applied:\")\n",
    "for i, step in enumerate(steps_applied, 1):\n",
    "    print(f\"  {i}. ‚úì {step}\")\n",
    "\n",
    "# Visualize preprocessing impact\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Before preprocessing - feature distributions\n",
    "numeric_cols = df_issues.select_dtypes(include=[np.number]).columns[:3]\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    if i < 3:\n",
    "        axes[i].hist(df_issues[col].dropna(), bins=30, alpha=0.7, color='lightcoral')\n",
    "        axes[i].set_title(f'Before: {col}', fontsize=10, fontweight='bold')\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# After preprocessing - show first 3 features\n",
    "for i in range(3):\n",
    "    if i < X_processed.shape[1]:\n",
    "        axes[i+3].hist(X_processed[:, i], bins=30, alpha=0.7, color='lightblue')\n",
    "        axes[i+3].set_title(f'After: Feature {i+1}', fontsize=10, fontweight='bold')\n",
    "        axes[i+3].set_ylabel('Frequency')\n",
    "        axes[i+3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save intelligent preprocessing visualization\n",
    "save_preprocessing_figure(fig, 'intelligent_preprocessing_impact', \n",
    "                         'Impact of intelligent preprocessing on data distributions')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüéØ Key Data Quality Improvements:\")\n",
    "print(f\"  ‚Ä¢ Missing values handled: {df_issues.isnull().sum().sum()} ‚Üí 0\")\n",
    "print(f\"  ‚Ä¢ Outliers detected and handled in numeric features\")\n",
    "print(f\"  ‚Ä¢ Categorical variables encoded appropriately\")\n",
    "print(f\"  ‚Ä¢ Features normalized for consistent scaling\")\n",
    "print(f\"  ‚Ä¢ Low-variance features removed automatically\")\n",
    "\n",
    "# Save intelligent preprocessor and results\n",
    "intelligent_preprocessor_metadata = {\n",
    "    'handle_missing': True,\n",
    "    'handle_outliers': True,\n",
    "    'normalize_features': True,\n",
    "    'encode_categoricals': True,\n",
    "    'feature_selection': True,\n",
    "    'original_shape': df_issues.shape,\n",
    "    'processed_shape': X_processed.shape,\n",
    "    'steps_applied': steps_applied,\n",
    "    'analysis': analysis\n",
    "}\n",
    "\n",
    "save_custom_transformer(preprocessor, \"intelligent_preprocessor\",\n",
    "                       \"Intelligent adaptive preprocessor with all features enabled\",\n",
    "                       intelligent_preprocessor_metadata)\n",
    "\n",
    "save_experiment_results('intelligent_preprocessing', intelligent_preprocessor_metadata,\n",
    "                       'Results from intelligent preprocessing analysis', 'intelligent_preprocessing')\n",
    "\n",
    "print(\"\\n‚ú® Intelligent preprocessing successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d97bd",
   "metadata": {},
   "source": [
    "### 4.1 Categorical and Numerical Preprocessing Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b383b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different categorical encoding methods\n",
    "print(\"üè∑Ô∏è Comparing Categorical Encoding Methods...\")\n",
    "\n",
    "# Create test data with various cardinalities\n",
    "np.random.seed(42)\n",
    "cat_data = pd.DataFrame({\n",
    "    'low_card': np.random.choice(['Red', 'Green', 'Blue'], 300),\n",
    "    'med_card': np.random.choice([f'Brand_{i}' for i in range(15)], 300),\n",
    "    'high_card': np.random.choice([f'ID_{i}' for i in range(80)], 300),\n",
    "    'ordinal': np.random.choice(['Low', 'Medium', 'High'], 300)\n",
    "})\n",
    "\n",
    "y_cat = np.random.randint(0, 2, 300)\n",
    "\n",
    "encoding_methods = ['onehot', 'label', 'target', 'binary']\n",
    "encoding_method_results = {}\n",
    "\n",
    "print(\"\\n--- Categorical Encoding Comparison ---\")\n",
    "for method in encoding_methods:\n",
    "    try:\n",
    "        encoder = CategoricalEncoder(encoding_type=method)\n",
    "        X_encoded = encoder.fit_transform(cat_data, y_cat)\n",
    "        \n",
    "        encoding_method_results[method] = {\n",
    "            'features_created': X_encoded.shape[1],\n",
    "            'memory_efficient': X_encoded.shape[1] <= 20,  # Arbitrary threshold\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "        print(f\"  {method.upper()}: {cat_data.shape[1]} ‚Üí {X_encoded.shape[1]} features\")\n",
    "    except Exception as e:\n",
    "        encoding_method_results[method] = {'success': False, 'error': str(e)}\n",
    "        print(f\"  {method.upper()}: ‚ùå Failed - {str(e)}\")\n",
    "\n",
    "# Visualize encoding comparison\n",
    "successful_methods = [m for m in encoding_method_results if encoding_method_results[m].get('success', False)]\n",
    "if successful_methods:\n",
    "    feature_counts = [encoding_method_results[m]['features_created'] for m in successful_methods]\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['lightblue', 'lightcoral', 'lightgreen', 'lightyellow'][:len(successful_methods)]\n",
    "    bars = plt.bar(successful_methods, feature_counts, color=colors, alpha=0.7)\n",
    "    plt.title('Feature Count by Encoding Method', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Encoding Method')\n",
    "    plt.ylabel('Number of Features Created')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels and efficiency indicators\n",
    "    for bar, method, count in zip(bars, successful_methods, feature_counts):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                str(count), ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Add efficiency indicator\n",
    "        if encoding_method_results[method]['memory_efficient']:\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2, \n",
    "                    '‚úì', ha='center', va='center', fontsize=20, color='white', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save categorical encoding comparison\n",
    "    save_preprocessing_figure(plt.gcf(), 'categorical_encoding_comparison', \n",
    "                             'Comparison of categorical encoding methods')\n",
    "    plt.show()\n",
    "    \n",
    "    # Performance summary\n",
    "    print(\"\\nüìä Encoding Method Analysis:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Method':<12} {'Features':<10} {'Efficient':<12} {'Recommendation':<25}\")\n",
    "    print(\"=\" * 60)\n",
    "    for method in successful_methods:\n",
    "        result = encoding_method_results[method]\n",
    "        efficient = \"Yes\" if result['memory_efficient'] else \"No\"\n",
    "        if result['features_created'] <= 10:\n",
    "            rec = \"Great for small datasets\"\n",
    "        elif result['features_created'] <= 30:\n",
    "            rec = \"Good for medium datasets\"\n",
    "        else:\n",
    "            rec = \"Use with caution\"\n",
    "        \n",
    "        print(f\"{method.upper():<12} {result['features_created']:<10} {efficient:<12} {rec:<25}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "save_experiment_results('categorical_encoding_comparison', encoding_method_results,\n",
    "                       'Comparison of categorical encoding methods', 'encoding')\n",
    "\n",
    "print(\"\\n‚ú® Categorical encoding comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a01e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare numerical transformation methods\n",
    "print(\"üî¢ Comparing Numerical Transformation Methods...\")\n",
    "\n",
    "# Create test data with different distributions\n",
    "np.random.seed(42)\n",
    "num_data = pd.DataFrame({\n",
    "    'normal': np.random.randn(400),\n",
    "    'skewed': np.random.exponential(2, 400),\n",
    "    'uniform': np.random.uniform(0, 100, 400),\n",
    "    'bimodal': np.concatenate([np.random.randn(200) - 2, np.random.randn(200) + 2])\n",
    "})\n",
    "\n",
    "transformation_methods = ['standard', 'minmax', 'robust', 'quantile']\n",
    "numerical_transformation_results = {}\n",
    "\n",
    "print(\"\\n--- Numerical Transformation Analysis ---\")\n",
    "\n",
    "# Calculate statistics before transformation\n",
    "original_stats = {}\n",
    "for col in num_data.columns:\n",
    "    original_stats[col] = {\n",
    "        'mean': num_data[col].mean(),\n",
    "        'std': num_data[col].std(),\n",
    "        'min': num_data[col].min(),\n",
    "        'max': num_data[col].max(),\n",
    "        'skewness': num_data[col].skew()\n",
    "    }\n",
    "\n",
    "# Apply transformations and analyze\n",
    "for method in transformation_methods:\n",
    "    transformer = NumericalTransformer(method=method)\n",
    "    data_transformed = transformer.fit_transform(num_data)\n",
    "    \n",
    "    # Calculate post-transformation statistics\n",
    "    transformed_stats = {}\n",
    "    for i, col in enumerate(num_data.columns):\n",
    "        transformed_stats[col] = {\n",
    "            'mean': data_transformed[:, i].mean(),\n",
    "            'std': data_transformed[:, i].std(),\n",
    "            'min': data_transformed[:, i].min(),\n",
    "            'max': data_transformed[:, i].max(),\n",
    "            'skewness': pd.Series(data_transformed[:, i]).skew()\n",
    "        }\n",
    "    \n",
    "    numerical_transformation_results[method] = {\n",
    "        'original': original_stats,\n",
    "        'transformed': transformed_stats,\n",
    "        'data': data_transformed\n",
    "    }\n",
    "    \n",
    "    print(f\"  {method.upper()}: Applied successfully\")\n",
    "\n",
    "# Visualize transformations\n",
    "fig, axes = plt.subplots(len(transformation_methods) + 1, num_data.shape[1], \n",
    "                        figsize=(16, 14))\n",
    "\n",
    "# Plot original distributions\n",
    "for i, col in enumerate(num_data.columns):\n",
    "    axes[0, i].hist(num_data[col], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "    axes[0, i].set_title(f'Original: {col}', fontsize=10, fontweight='bold')\n",
    "    axes[0, i].set_ylabel('Frequency')\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f'Œº={original_stats[col][\"mean\"]:.2f}\\nœÉ={original_stats[col][\"std\"]:.2f}'\n",
    "    axes[0, i].text(0.02, 0.98, stats_text, transform=axes[0, i].transAxes,\n",
    "                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Apply and plot each transformation\n",
    "colors = ['lightblue', 'lightgreen', 'lightyellow', 'lightpink']\n",
    "for row, method in enumerate(transformation_methods, 1):\n",
    "    data_transformed = numerical_transformation_results[method]['data']\n",
    "    \n",
    "    for i, col in enumerate(num_data.columns):\n",
    "        axes[row, i].hist(data_transformed[:, i], bins=30, alpha=0.7, \n",
    "                         color=colors[row-1], edgecolor='black')\n",
    "        axes[row, i].set_title(f'{method.title()}: {col}', fontsize=10, fontweight='bold')\n",
    "        axes[row, i].set_ylabel('Frequency')\n",
    "        axes[row, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add transformed statistics\n",
    "        stats = numerical_transformation_results[method]['transformed'][col]\n",
    "        stats_text = f'Œº={stats[\"mean\"]:.2f}\\nœÉ={stats[\"std\"]:.2f}'\n",
    "        axes[row, i].text(0.02, 0.98, stats_text, transform=axes[row, i].transAxes,\n",
    "                         verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save numerical transformation comparison\n",
    "save_preprocessing_figure(fig, 'numerical_transformation_comparison', \n",
    "                         'Comparison of numerical transformation methods')\n",
    "plt.show()\n",
    "\n",
    "# Summarize transformation effectiveness\n",
    "print(\"\\nüìä Transformation Effectiveness Summary:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Method':<12} {'Best For':<25} {'Mean Range':<15} {'Std Range':<15}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "method_recommendations = {\n",
    "    'standard': 'Normal distributions',\n",
    "    'minmax': 'Bounded features (0-1)',\n",
    "    'robust': 'Data with outliers',\n",
    "    'quantile': 'Non-linear distributions'\n",
    "}\n",
    "\n",
    "for method in transformation_methods:\n",
    "    means = [numerical_transformation_results[method]['transformed'][col]['mean'] for col in num_data.columns]\n",
    "    stds = [numerical_transformation_results[method]['transformed'][col]['std'] for col in num_data.columns]\n",
    "    \n",
    "    mean_range = f\"{min(means):.2f} to {max(means):.2f}\"\n",
    "    std_range = f\"{min(stds):.2f} to {max(stds):.2f}\"\n",
    "    \n",
    "    print(f\"{method.upper():<12} {method_recommendations[method]:<25} {mean_range:<15} {std_range:<15}\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüéØ Key Insights:\")\n",
    "print(\"  ‚Ä¢ Standard scaling centers data around mean=0, std=1\")\n",
    "print(\"  ‚Ä¢ MinMax scaling bounds all features to [0,1] range\")\n",
    "print(\"  ‚Ä¢ Robust scaling is less sensitive to outliers\")\n",
    "print(\"  ‚Ä¢ Quantile transformation creates uniform distributions\")\n",
    "\n",
    "save_experiment_results('numerical_transformation_comparison', numerical_transformation_results,\n",
    "                       'Comparison of numerical transformation methods', 'transformation')\n",
    "\n",
    "print(\"\\n‚ú® Numerical transformation comparison complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb28122",
   "metadata": {},
   "source": [
    "## 5. Pipeline Factory Patterns {#pipeline-factory}\n",
    "\n",
    "The PipelineFactory creates optimized preprocessing pipelines automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9491ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate PipelineFactory\n",
    "print(\"üè≠ Testing PipelineFactory...\")\n",
    "\n",
    "# Generate comprehensive test dataset\n",
    "generator = SyntheticDataGenerator(random_state=42)\n",
    "X_comprehensive, y_comprehensive = generator.mixed_data_types(\n",
    "    n_samples=1000,\n",
    "    n_numerical=10,\n",
    "    n_categorical=5,\n",
    "    n_ordinal=3,\n",
    "    missing_rate=0.1,\n",
    "    outlier_rate=0.05\n",
    ")\n",
    "\n",
    "print(f\"Generated comprehensive dataset: {X_comprehensive.shape}\")\n",
    "print(f\"Data characteristics:\")\n",
    "print(f\"  ‚Ä¢ Numerical features: {len(X_comprehensive.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"  ‚Ä¢ Categorical features: {len(X_comprehensive.select_dtypes(include=['object']).columns)}\")\n",
    "print(f\"  ‚Ä¢ Missing values: {X_comprehensive.isnull().sum().sum()}\")\n",
    "\n",
    "# Initialize pipeline factory\n",
    "factory = PipelineFactory()\n",
    "\n",
    "# Create different types of pipelines\n",
    "pipeline_types = ['basic', 'advanced', 'full']\n",
    "pipelines = {}\n",
    "pipeline_details = {}\n",
    "\n",
    "print(\"\\n--- Pipeline Creation Results ---\")\n",
    "for pipeline_type in pipeline_types:\n",
    "    pipeline = factory.create_preprocessing_pipeline(\n",
    "        X_comprehensive, y_comprehensive, \n",
    "        pipeline_type=pipeline_type\n",
    "    )\n",
    "    pipelines[pipeline_type] = pipeline\n",
    "    \n",
    "    # Store pipeline details\n",
    "    pipeline_details[pipeline_type] = {\n",
    "        'steps': len(pipeline.steps),\n",
    "        'step_names': [name for name, _ in pipeline.steps]\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nüîß {pipeline_type.title()} Pipeline ({len(pipeline.steps)} steps):\")\n",
    "    for i, (name, transformer) in enumerate(pipeline.steps):\n",
    "        print(f\"  {i+1}. {name}: {transformer.__class__.__name__}\")\n",
    "\n",
    "# Compare pipeline performance\n",
    "print(\"\\nüìà Pipeline Performance Comparison...\")\n",
    "\n",
    "# Test each pipeline with a classifier\n",
    "classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "factory_results = {}\n",
    "\n",
    "for name, preprocessing_pipeline in pipelines.items():\n",
    "    try:\n",
    "        # Create full pipeline with classifier\n",
    "        full_pipeline = Pipeline([\n",
    "            ('preprocessing', preprocessing_pipeline),\n",
    "            ('classifier', classifier)\n",
    "        ])\n",
    "        \n",
    "        # Cross-validation\n",
    "        scores = cross_val_score(full_pipeline, X_comprehensive, y_comprehensive, \n",
    "                               cv=5, scoring='accuracy')\n",
    "        \n",
    "        # Fit to get feature info\n",
    "        full_pipeline.fit(X_comprehensive, y_comprehensive)\n",
    "        processed_features = preprocessing_pipeline.transform(X_comprehensive).shape[1]\n",
    "        \n",
    "        factory_results[name] = {\n",
    "            'mean_score': scores.mean(),\n",
    "            'std_score': scores.std(),\n",
    "            'scores': scores,\n",
    "            'processed_features': processed_features,\n",
    "            'pipeline_steps': len(preprocessing_pipeline.steps)\n",
    "        }\n",
    "        \n",
    "        print(f\"  {name.title()}: {scores.mean():.3f} ¬± {scores.std():.3f} \"\n",
    "              f\"({processed_features} features)\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  {name.title()}: ‚ùå Failed - {str(e)}\")\n",
    "        factory_results[name] = {'error': str(e)}\n",
    "\n",
    "# Visualize results\n",
    "if factory_results and all('error' not in r for r in factory_results.values()):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    pipeline_names = list(factory_results.keys())\n",
    "    mean_scores = [factory_results[name]['mean_score'] for name in pipeline_names]\n",
    "    std_scores = [factory_results[name]['std_score'] for name in pipeline_names]\n",
    "    feature_counts = [factory_results[name]['processed_features'] for name in pipeline_names]\n",
    "    step_counts = [factory_results[name]['pipeline_steps'] for name in pipeline_names]\n",
    "    \n",
    "    colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "    \n",
    "    # Performance comparison\n",
    "    bars1 = axes[0].bar(pipeline_names, mean_scores, yerr=std_scores, capsize=5, \n",
    "                       color=colors, alpha=0.7)\n",
    "    axes[0].set_title('Pipeline Performance Comparison', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Pipeline Type')\n",
    "    axes[0].set_ylabel('Cross-Validation Accuracy')\n",
    "    axes[0].set_ylim(0.5, 1.0)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, score in zip(bars1, mean_scores):\n",
    "        axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{score:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Feature count comparison\n",
    "    bars2 = axes[1].bar(pipeline_names, feature_counts, color=colors, alpha=0.7)\n",
    "    axes[1].set_title('Features After Processing', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Pipeline Type')\n",
    "    axes[1].set_ylabel('Number of Features')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, count in zip(bars2, feature_counts):\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                    str(count), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Pipeline complexity\n",
    "    bars3 = axes[2].bar(pipeline_names, step_counts, color=colors, alpha=0.7)\n",
    "    axes[2].set_title('Pipeline Complexity', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_xlabel('Pipeline Type')\n",
    "    axes[2].set_ylabel('Number of Steps')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, steps in zip(bars3, step_counts):\n",
    "        axes[2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                    str(steps), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save pipeline factory visualization\n",
    "    save_preprocessing_figure(fig, 'pipeline_factory_comparison', \n",
    "                             'Comparison of pipeline factory generated pipelines')\n",
    "    plt.show()\n",
    "    \n",
    "    # Detailed results table\n",
    "    print(\"\\nüìä Comprehensive Pipeline Analysis:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"{'Pipeline':<12} {'Accuracy':<12} {'¬±Std':<8} {'Features':<10} {'Steps':<8} {'Efficiency':<12}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for name in pipeline_names:\n",
    "        r = factory_results[name]\n",
    "        efficiency = r['mean_score'] / r['pipeline_steps']  # Performance per step\n",
    "        print(f\"{name.title():<12} {r['mean_score']:<12.3f} {r['std_score']:<8.3f} \"\n",
    "              f\"{r['processed_features']:<10} {r['pipeline_steps']:<8} {efficiency:<12.3f}\")\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Recommendations\n",
    "    best_performance = max(pipeline_names, key=lambda x: factory_results[x]['mean_score'])\n",
    "    most_efficient = max(pipeline_names, key=lambda x: factory_results[x]['mean_score'] / factory_results[x]['pipeline_steps'])\n",
    "    \n",
    "    print(f\"\\nüéØ Pipeline Recommendations:\")\n",
    "    print(f\"  ‚Ä¢ Best Performance: {best_performance.title()} ({factory_results[best_performance]['mean_score']:.3f})\")\n",
    "    print(f\"  ‚Ä¢ Most Efficient: {most_efficient.title()} (efficiency: {factory_results[most_efficient]['mean_score']/factory_results[most_efficient]['pipeline_steps']:.3f})\")\n",
    "    print(f\"  ‚Ä¢ Feature Reduction: {X_comprehensive.shape[1]} ‚Üí {min(feature_counts)} features (best compression)\")\n",
    "\n",
    "# Save pipeline factory results and pipelines\n",
    "for pipeline_type, pipeline in pipelines.items():\n",
    "    pipeline_metadata = {\n",
    "        'pipeline_type': pipeline_type,\n",
    "        'steps_count': len(pipeline.steps),\n",
    "        'step_names': [name for name, _ in pipeline.steps]\n",
    "    }\n",
    "    if pipeline_type in factory_results and 'error' not in factory_results[pipeline_type]:\n",
    "        pipeline_metadata.update(factory_results[pipeline_type])\n",
    "    \n",
    "    save_preprocessing_pipeline(pipeline, f\"factory_{pipeline_type}\",\n",
    "                               f\"Pipeline factory generated {pipeline_type} pipeline\",\n",
    "                               pipeline_metadata)\n",
    "\n",
    "save_experiment_results('pipeline_factory_comparison', factory_results,\n",
    "                       'Results from pipeline factory comparison', 'pipeline_factory')\n",
    "\n",
    "print(\"\\n‚ú® PipelineFactory successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac5f955",
   "metadata": {},
   "source": [
    "## 6. Data Validation and Quality {#data-validation}\n",
    "\n",
    "Comprehensive data validation to ensure preprocessing quality and catch issues early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38134f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate data validation capabilities\n",
    "print(\"üîç Testing Data Validation and Quality Checks...\")\n",
    "\n",
    "# Create dataset with various quality issues\n",
    "np.random.seed(42)\n",
    "problematic_data = pd.DataFrame({\n",
    "    'good_feature': np.random.randn(500),\n",
    "    'missing_heavy': [np.nan if i % 3 == 0 else np.random.randn() for i in range(500)],\n",
    "    'constant_feature': np.full(500, 42),\n",
    "    'nearly_constant': np.random.choice([1, 2], 500, p=[0.98, 0.02]),\n",
    "    'duplicate_info': np.random.randint(0, 10, 500),\n",
    "    'high_cardinality_cat': [f'ID_{i}' for i in range(500)],  # Unique IDs\n",
    "    'outlier_prone': np.concatenate([np.random.randn(450), np.random.randn(50) * 10])\n",
    "})\n",
    "\n",
    "# Add exact duplicates for demonstration\n",
    "problematic_data.loc[500] = problematic_data.loc[0]  # Add exact duplicate row\n",
    "\n",
    "y_validation = np.random.randint(0, 2, len(problematic_data))\n",
    "\n",
    "print(f\"Created problematic dataset: {problematic_data.shape}\")\n",
    "print(f\"Dataset info:\")\n",
    "print(problematic_data.info())\n",
    "\n",
    "# Initialize validator\n",
    "validator = DataValidator()\n",
    "\n",
    "# Perform comprehensive validation\n",
    "print(\"\\n--- Data Quality Validation Results ---\")\n",
    "validation_results = validator.validate_dataset(problematic_data, y_validation)\n",
    "\n",
    "# Display validation results\n",
    "severity_counts = {'INFO': 0, 'WARNING': 0, 'ERROR': 0, 'CRITICAL': 0}\n",
    "\n",
    "for check_name, result in validation_results.items():\n",
    "    severity = result['severity']\n",
    "    status = result['status']\n",
    "    message = result['message']\n",
    "    \n",
    "    severity_counts[severity] += 1\n",
    "    \n",
    "    # Color code based on severity\n",
    "    icon = {'INFO': '‚ÑπÔ∏è', 'WARNING': '‚ö†Ô∏è', 'ERROR': '‚ùå', 'CRITICAL': 'üö®'}[severity]\n",
    "    print(f\"  {icon} [{severity}] {check_name}: {message}\")\n",
    "\n",
    "# Generate quality report\n",
    "print(f\"\\nüìä Data Quality Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total Checks Performed: {len(validation_results)}\")\n",
    "for severity, count in severity_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{severity} Issues: {count}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Visualize data quality issues\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# 1. Missing values heatmap\n",
    "missing_data = problematic_data.isnull()\n",
    "if missing_data.any().any():\n",
    "    im1 = axes[0].imshow(missing_data.T, cmap='RdYlBu_r', aspect='auto')\n",
    "    axes[0].set_title('Missing Values Pattern', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Samples')\n",
    "    axes[0].set_ylabel('Features')\n",
    "    axes[0].set_yticks(range(len(problematic_data.columns)))\n",
    "    axes[0].set_yticklabels(problematic_data.columns, fontsize=8)\n",
    "\n",
    "# 2. Feature variance analysis\n",
    "numeric_cols = problematic_data.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_cols) > 0:\n",
    "    variances = problematic_data[numeric_cols].var()\n",
    "    bars2 = axes[1].bar(range(len(variances)), variances, color='lightblue', alpha=0.7)\n",
    "    axes[1].set_title('Feature Variance Analysis', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('Features')\n",
    "    axes[1].set_ylabel('Variance')\n",
    "    axes[1].set_xticks(range(len(variances)))\n",
    "    axes[1].set_xticklabels(variances.index, rotation=45, ha='right', fontsize=8)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Outlier detection visualization\n",
    "outlier_feature = 'outlier_prone'\n",
    "if outlier_feature in problematic_data.columns:\n",
    "    axes[2].boxplot(problematic_data[outlier_feature].dropna())\n",
    "    axes[2].set_title('Outlier Detection Example', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_ylabel('Values')\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Cardinality analysis\n",
    "categorical_cols = problematic_data.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    cardinalities = [problematic_data[col].nunique() for col in categorical_cols]\n",
    "    bars4 = axes[3].bar(range(len(cardinalities)), cardinalities, color='lightcoral', alpha=0.7)\n",
    "    axes[3].set_title('Categorical Feature Cardinality', fontsize=12, fontweight='bold')\n",
    "    axes[3].set_xlabel('Categorical Features')\n",
    "    axes[3].set_ylabel('Unique Values')\n",
    "    axes[3].set_xticks(range(len(cardinalities)))\n",
    "    axes[3].set_xticklabels(categorical_cols, rotation=45, ha='right', fontsize=8)\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Data distribution overview\n",
    "feature_for_dist = 'good_feature'\n",
    "if feature_for_dist in problematic_data.columns:\n",
    "    axes[4].hist(problematic_data[feature_for_dist].dropna(), bins=30, \n",
    "                color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "    axes[4].set_title('Sample Feature Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[4].set_xlabel('Values')\n",
    "    axes[4].set_ylabel('Frequency')\n",
    "    axes[4].grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Severity summary pie chart\n",
    "severity_data = [count for count in severity_counts.values() if count > 0]\n",
    "severity_labels = [sev for sev, count in severity_counts.items() if count > 0]\n",
    "colors_pie = ['lightblue', 'yellow', 'orange', 'red'][:len(severity_data)]\n",
    "\n",
    "if severity_data:\n",
    "    axes[5].pie(severity_data, labels=severity_labels, colors=colors_pie, \n",
    "               autopct='%1.1f%%', startangle=90)\n",
    "    axes[5].set_title('Validation Issues by Severity', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save data quality visualization\n",
    "save_preprocessing_figure(fig, 'data_quality_analysis', \n",
    "                         'Data quality assessment and validation results')\n",
    "plt.show()\n",
    "\n",
    "# Provide actionable recommendations\n",
    "print(\"\\nüéØ Data Quality Recommendations:\")\n",
    "recommendations = []\n",
    "\n",
    "if severity_counts['CRITICAL'] > 0:\n",
    "    recommendations.append(\"üö® Address CRITICAL issues immediately before proceeding\")\n",
    "if severity_counts['ERROR'] > 0:\n",
    "    recommendations.append(\"‚ùå Fix ERROR-level issues to ensure model reliability\")\n",
    "if severity_counts['WARNING'] > 0:\n",
    "    recommendations.append(\"‚ö†Ô∏è Review WARNING issues for potential improvements\")\n",
    "\n",
    "# Specific recommendations based on common issues\n",
    "if problematic_data.isnull().any().any():\n",
    "    recommendations.append(\"üîß Implement missing value imputation strategy\")\n",
    "if (problematic_data.var() == 0).any():\n",
    "    recommendations.append(\"üóëÔ∏è Remove constant features that provide no information\")\n",
    "if problematic_data.duplicated().any():\n",
    "    recommendations.append(\"üîÑ Remove duplicate rows to prevent data leakage\")\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"  {i}. {rec}\")\n",
    "\n",
    "if not recommendations:\n",
    "    print(\"  ‚úÖ Data quality is good! No major issues detected.\")\n",
    "\n",
    "# Save validation results\n",
    "validation_summary = {\n",
    "    'total_checks': len(validation_results),\n",
    "    'severity_counts': severity_counts,\n",
    "    'recommendations': recommendations,\n",
    "    'validation_details': validation_results\n",
    "}\n",
    "\n",
    "save_experiment_results('data_validation_analysis', validation_summary,\n",
    "                       'Comprehensive data quality validation analysis', 'data_validation')\n",
    "\n",
    "print(\"\\n‚ú® Data validation and quality assessment complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6230ecfc",
   "metadata": {},
   "source": [
    "## 7. Advanced Pipeline Techniques {#advanced-techniques}\n",
    "\n",
    "Explore advanced pipeline patterns including conditional processing and adaptive strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a38be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate advanced pipeline techniques\n",
    "print(\"üî¨ Testing Advanced Pipeline Techniques...\")\n",
    "\n",
    "# Create complex dataset requiring sophisticated preprocessing\n",
    "np.random.seed(42)\n",
    "complex_data = pd.DataFrame({\n",
    "    # Numerical features with different characteristics\n",
    "    'normal_nums': np.random.randn(600),\n",
    "    'skewed_nums': np.random.exponential(2, 600),\n",
    "    'bounded_nums': np.random.uniform(0, 100, 600),\n",
    "    \n",
    "    # Categorical features with different cardinalities\n",
    "    'low_cat': np.random.choice(['A', 'B', 'C'], 600),\n",
    "    'medium_cat': np.random.choice([f'Cat_{i}' for i in range(20)], 600),\n",
    "    'high_cat': np.random.choice([f'ID_{i}' for i in range(200)], 600),\n",
    "    \n",
    "    # Features with specific issues\n",
    "    'with_outliers': np.concatenate([np.random.randn(550), np.random.randn(50) * 5]),\n",
    "    'mostly_missing': [np.nan if i % 4 == 0 else np.random.randn() for i in range(600)],\n",
    "    'constant_val': np.full(600, 123),\n",
    "    \n",
    "    # Text-like categorical\n",
    "    'text_feature': [f'Text_{np.random.randint(0, 50)}' for _ in range(600)]\n",
    "})\n",
    "\n",
    "y_complex = np.random.randint(0, 3, 600)  # 3-class problem\n",
    "\n",
    "print(f\"Complex dataset created: {complex_data.shape}\")\n",
    "print(f\"Data types distribution: {complex_data.dtypes.value_counts().to_dict()}\")\n",
    "\n",
    "# Advanced pipeline with conditional processing\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "class AdaptivePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Advanced preprocessor that adapts to data characteristics.\"\"\"\n",
    "    \n",
    "    def __init__(self, variance_threshold=0.01, cardinality_threshold=50):\n",
    "        self.variance_threshold = variance_threshold\n",
    "        self.cardinality_threshold = cardinality_threshold\n",
    "        self.feature_strategies_ = {}\n",
    "        self.preprocessors_ = {}\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Analyze each feature and determine optimal strategy\n",
    "        for column in X.columns:\n",
    "            feature_info = self._analyze_feature(X[column])\n",
    "            strategy = self._determine_strategy(feature_info)\n",
    "            self.feature_strategies_[column] = strategy\n",
    "            \n",
    "            # Create and fit appropriate preprocessor\n",
    "            if strategy['type'] == 'drop':\n",
    "                continue\n",
    "            elif strategy['type'] == 'numerical':\n",
    "                if strategy['method'] == 'robust':\n",
    "                    from sklearn.preprocessing import RobustScaler\n",
    "                    preprocessor = RobustScaler()\n",
    "                else:\n",
    "                    preprocessor = StandardScaler()\n",
    "                preprocessor.fit(X[[column]].fillna(X[column].mean()))\n",
    "                self.preprocessors_[column] = preprocessor\n",
    "            elif strategy['type'] == 'categorical':\n",
    "                if strategy['method'] == 'onehot':\n",
    "                    from sklearn.preprocessing import OneHotEncoder\n",
    "                    preprocessor = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "                else:\n",
    "                    preprocessor = LabelEncoder()\n",
    "                preprocessor.fit(X[column].fillna('missing'))\n",
    "                self.preprocessors_[column] = preprocessor\n",
    "                \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_features = []\n",
    "        feature_names = []\n",
    "        \n",
    "        for column in X.columns:\n",
    "            if column not in self.feature_strategies_:\n",
    "                continue\n",
    "                \n",
    "            strategy = self.feature_strategies_[column]\n",
    "            \n",
    "            if strategy['type'] == 'drop':\n",
    "                continue\n",
    "            elif strategy['type'] == 'numerical':\n",
    "                data = X[[column]].fillna(X[column].mean())\n",
    "                transformed = self.preprocessors_[column].transform(data)\n",
    "                transformed_features.append(transformed)\n",
    "                feature_names.append(column)\n",
    "            elif strategy['type'] == 'categorical':\n",
    "                data = X[column].fillna('missing')\n",
    "                if strategy['method'] == 'onehot':\n",
    "                    transformed = self.preprocessors_[column].transform(data.values.reshape(-1, 1))\n",
    "                    transformed_features.append(transformed)\n",
    "                    # Generate feature names for one-hot encoded features\n",
    "                    categories = self.preprocessors_[column].categories_[0]\n",
    "                    feature_names.extend([f\"{column}_{cat}\" for cat in categories])\n",
    "                else:\n",
    "                    transformed = self.preprocessors_[column].transform(data).reshape(-1, 1)\n",
    "                    transformed_features.append(transformed)\n",
    "                    feature_names.append(column)\n",
    "        \n",
    "        if transformed_features:\n",
    "            result = np.hstack(transformed_features)\n",
    "            return result\n",
    "        else:\n",
    "            return np.empty((X.shape[0], 0))\n",
    "    \n",
    "    def _analyze_feature(self, series):\n",
    "        \"\"\"Analyze feature characteristics.\"\"\"\n",
    "        info = {\n",
    "            'dtype': series.dtype,\n",
    "            'missing_rate': series.isnull().mean(),\n",
    "            'unique_count': series.nunique(),\n",
    "            'total_count': len(series)\n",
    "        }\n",
    "        \n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            non_null_series = series.dropna()\n",
    "            if len(non_null_series) > 0:\n",
    "                info.update({\n",
    "                    'variance': non_null_series.var(),\n",
    "                    'skewness': non_null_series.skew(),\n",
    "                    'outlier_rate': self._estimate_outlier_rate(non_null_series)\n",
    "                })\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def _determine_strategy(self, feature_info):\n",
    "        \"\"\"Determine preprocessing strategy based on feature characteristics.\"\"\"\n",
    "        # Check if feature should be dropped\n",
    "        if (feature_info.get('variance', 1) < self.variance_threshold or \n",
    "            feature_info['missing_rate'] > 0.8 or\n",
    "            feature_info['unique_count'] <= 1):\n",
    "            return {'type': 'drop', 'reason': 'low_information'}\n",
    "        \n",
    "        # Numerical features\n",
    "        if pd.api.types.is_numeric_dtype(feature_info['dtype']):\n",
    "            if feature_info.get('outlier_rate', 0) > 0.1:\n",
    "                return {'type': 'numerical', 'method': 'robust'}\n",
    "            else:\n",
    "                return {'type': 'numerical', 'method': 'standard'}\n",
    "        \n",
    "        # Categorical features\n",
    "        else:\n",
    "            if feature_info['unique_count'] > self.cardinality_threshold:\n",
    "                return {'type': 'categorical', 'method': 'label'}\n",
    "            else:\n",
    "                return {'type': 'categorical', 'method': 'onehot'}\n",
    "    \n",
    "    def _estimate_outlier_rate(self, series):\n",
    "        \"\"\"Estimate outlier rate using IQR method.\"\"\"\n",
    "        Q1 = series.quantile(0.25)\n",
    "        Q3 = series.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = ((series < lower_bound) | (series > upper_bound)).sum()\n",
    "        return outliers / len(series)\n",
    "    \n",
    "    def get_feature_strategies(self):\n",
    "        \"\"\"Get summary of strategies applied to each feature.\"\"\"\n",
    "        return self.feature_strategies_\n",
    "\n",
    "# Test the adaptive preprocessor\n",
    "print(\"\\n--- Testing Adaptive Preprocessor ---\")\n",
    "adaptive_preprocessor = AdaptivePreprocessor()\n",
    "adaptive_preprocessor.fit(complex_data, y_complex)\n",
    "\n",
    "# Get preprocessing strategies\n",
    "strategies = adaptive_preprocessor.get_feature_strategies()\n",
    "print(\"\\nFeature Processing Strategies:\")\n",
    "for feature, strategy in strategies.items():\n",
    "    print(f\"  {feature}: {strategy}\")\n",
    "\n",
    "# Transform the data\n",
    "X_adaptive = adaptive_preprocessor.transform(complex_data)\n",
    "print(f\"\\nTransformation Results:\")\n",
    "print(f\"  Original shape: {complex_data.shape}\")\n",
    "print(f\"  Transformed shape: {X_adaptive.shape}\")\n",
    "print(f\"  Features retained: {X_adaptive.shape[1]} / {complex_data.shape[1]}\")\n",
    "\n",
    "# Compare with standard preprocessing\n",
    "standard_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Only use numerical columns for standard pipeline\n",
    "numerical_cols = complex_data.select_dtypes(include=[np.number]).columns\n",
    "if len(numerical_cols) > 0:\n",
    "    X_standard = standard_pipeline.fit_transform(complex_data[numerical_cols])\n",
    "    print(f\"  Standard pipeline shape: {X_standard.shape}\")\n",
    "\n",
    "    # Performance comparison with classification\n",
    "    classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "    # Test adaptive preprocessing\n",
    "    scores_adaptive = cross_val_score(classifier, X_adaptive, y_complex, cv=5, scoring='accuracy')\n",
    "\n",
    "    # Test standard preprocessing  \n",
    "    scores_standard = cross_val_score(classifier, X_standard, y_complex, cv=5, scoring='accuracy')\n",
    "\n",
    "    print(f\"\\nüìà Performance Comparison:\")\n",
    "    print(f\"  Adaptive Preprocessing: {scores_adaptive.mean():.3f} ¬± {scores_adaptive.std():.3f}\")\n",
    "    print(f\"  Standard Preprocessing: {scores_standard.mean():.3f} ¬± {scores_standard.std():.3f}\")\n",
    "    print(f\"  Improvement: {((scores_adaptive.mean() - scores_standard.mean()) / scores_standard.mean() * 100):.1f}%\")\n",
    "\n",
    "# Save adaptive preprocessor and results\n",
    "adaptive_metadata = {\n",
    "    'variance_threshold': 0.01,\n",
    "    'cardinality_threshold': 50,\n",
    "    'feature_strategies': strategies,\n",
    "    'original_shape': complex_data.shape,\n",
    "    'transformed_shape': X_adaptive.shape,\n",
    "    'adaptive_score': scores_adaptive.mean() if 'scores_adaptive' in locals() else None,\n",
    "    'standard_score': scores_standard.mean() if 'scores_standard' in locals() else None\n",
    "}\n",
    "\n",
    "save_custom_transformer(adaptive_preprocessor, \"adaptive_preprocessor\",\n",
    "                       \"Advanced adaptive preprocessor with conditional processing\",\n",
    "                       adaptive_metadata)\n",
    "\n",
    "save_experiment_results('adaptive_preprocessing', adaptive_metadata,\n",
    "                       'Results from adaptive preprocessing analysis', 'advanced_techniques')\n",
    "\n",
    "print(\"\\n‚ú® Advanced pipeline techniques successfully demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bae669",
   "metadata": {},
   "source": [
    "## 8. Performance Comparison {#performance-comparison}\n",
    "\n",
    "Comprehensive preprocessing performance comparison across different strategies and datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dec863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive preprocessing performance comparison\n",
    "print(\"üèÅ Comprehensive Preprocessing Performance Comparison...\")\n",
    "\n",
    "# Generate diverse test datasets\n",
    "datasets = {}\n",
    "dataset_names = ['balanced', 'imbalanced', 'high_dimensional', 'mixed_types']\n",
    "\n",
    "print(\"\\n--- Generating Test Datasets ---\")\n",
    "for name in dataset_names:\n",
    "    if name == 'balanced':\n",
    "        X, y = generator.classification_dataset(n_samples=800, n_features=15, n_classes=2, class_sep=0.8)\n",
    "    elif name == 'imbalanced':\n",
    "        X, y = generator.imbalanced_classification(n_samples=800, n_features=12, imbalance_ratio=0.1)\n",
    "    elif name == 'high_dimensional':\n",
    "        X, y = generator.classification_dataset(n_samples=600, n_features=50, n_informative=20)\n",
    "    elif name == 'mixed_types':\n",
    "        X, y = generator.mixed_data_types(n_samples=700, n_numerical=8, n_categorical=6, n_ordinal=3)\n",
    "    \n",
    "    datasets[name] = (X, y)\n",
    "    print(f\"  {name}: {X.shape} - {np.bincount(y) if hasattr(y, '__len__') else 'regression'}\")\n",
    "\n",
    "# Define preprocessing strategies to compare\n",
    "preprocessing_strategies = {\n",
    "    'minimal': {\n",
    "        'description': 'Basic scaling only',\n",
    "        'pipeline': Pipeline([('scaler', StandardScaler())])\n",
    "    },\n",
    "    'standard': {\n",
    "        'description': 'Standard preprocessing',\n",
    "        'pipeline': None  # Will be created by DataPreprocessor\n",
    "    },\n",
    "    'intelligent': {\n",
    "        'description': 'Intelligent adaptive preprocessing',\n",
    "        'pipeline': None  # Will be created by DataPreprocessor with advanced options\n",
    "    },\n",
    "    'factory_basic': {\n",
    "        'description': 'Pipeline factory basic',\n",
    "        'pipeline': None  # Will be created by PipelineFactory\n",
    "    },\n",
    "    'factory_advanced': {\n",
    "        'description': 'Pipeline factory advanced',\n",
    "        'pipeline': None  # Will be created by PipelineFactory\n",
    "    }\n",
    "}\n",
    "\n",
    "# Performance results storage\n",
    "performance_results = {}\n",
    "\n",
    "print(\"\\n--- Testing Preprocessing Strategies ---\")\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"\\nüî¨ Testing on {dataset_name} dataset...\")\n",
    "    performance_results[dataset_name] = {}\n",
    "    \n",
    "    # Handle different data types appropriately\n",
    "    if hasattr(X, 'select_dtypes'):  # DataFrame\n",
    "        is_mixed_data = True\n",
    "    else:  # NumPy array\n",
    "        is_mixed_data = False\n",
    "        X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "    \n",
    "    for strategy_name, strategy_info in preprocessing_strategies.items():\n",
    "        try:\n",
    "            print(f\"    Testing {strategy_name}...\")\n",
    "            \n",
    "            # Create appropriate pipeline for each strategy\n",
    "            if strategy_name == 'minimal':\n",
    "                pipeline = strategy_info['pipeline']\n",
    "                # For minimal strategy, only use numerical columns\n",
    "                X_numeric = X.select_dtypes(include=[np.number])\n",
    "                if X_numeric.empty:\n",
    "                    print(f\"      ‚ö†Ô∏è Skipping {strategy_name} - no numerical features\")\n",
    "                    continue\n",
    "                X_processed = pipeline.fit_transform(X_numeric)\n",
    "                \n",
    "            elif strategy_name == 'standard':\n",
    "                preprocessor = DataPreprocessor(\n",
    "                    handle_missing=True,\n",
    "                    normalize_features=True,\n",
    "                    encode_categoricals=True\n",
    "                )\n",
    "                X_processed = preprocessor.fit_transform(X, y)\n",
    "                \n",
    "            elif strategy_name == 'intelligent':\n",
    "                preprocessor = DataPreprocessor(\n",
    "                    handle_missing=True,\n",
    "                    handle_outliers=True,\n",
    "                    normalize_features=True,\n",
    "                    encode_categoricals=True,\n",
    "                    feature_selection=True,\n",
    "                    create_interactions=False  # Keep complexity manageable\n",
    "                )\n",
    "                X_processed = preprocessor.fit_transform(X, y)\n",
    "                \n",
    "            elif strategy_name == 'factory_basic':\n",
    "                factory = PipelineFactory()\n",
    "                pipeline = factory.create_preprocessing_pipeline(X, y, pipeline_type='basic')\n",
    "                X_processed = pipeline.fit_transform(X)\n",
    "                \n",
    "            elif strategy_name == 'factory_advanced':\n",
    "                factory = PipelineFactory()\n",
    "                pipeline = factory.create_preprocessing_pipeline(X, y, pipeline_type='advanced')\n",
    "                X_processed = pipeline.fit_transform(X)\n",
    "            \n",
    "            # Evaluate preprocessing quality with machine learning\n",
    "            classifier = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "            scores = cross_val_score(classifier, X_processed, y, cv=5, scoring='accuracy')\n",
    "            \n",
    "            # Store results\n",
    "            performance_results[dataset_name][strategy_name] = {\n",
    "                'accuracy_mean': scores.mean(),\n",
    "                'accuracy_std': scores.std(),\n",
    "                'original_features': X.shape[1],\n",
    "                'processed_features': X_processed.shape[1],\n",
    "                'feature_reduction': (X.shape[1] - X_processed.shape[1]) / X.shape[1],\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            print(f\"      ‚úÖ Accuracy: {scores.mean():.3f} ¬± {scores.std():.3f}\")\n",
    "            print(f\"         Features: {X.shape[1]} ‚Üí {X_processed.shape[1]}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      ‚ùå Failed: {str(e)}\")\n",
    "            performance_results[dataset_name][strategy_name] = {\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            }\n",
    "\n",
    "# Analyze and visualize results\n",
    "print(\"\\nüìä Performance Analysis and Visualization...\")\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Prepare data for visualization\n",
    "successful_results = {}\n",
    "for dataset in performance_results:\n",
    "    successful_results[dataset] = {}\n",
    "    for strategy in performance_results[dataset]:\n",
    "        if performance_results[dataset][strategy].get('success', False):\n",
    "            successful_results[dataset][strategy] = performance_results[dataset][strategy]['accuracy_mean']\n",
    "\n",
    "# 1. Overall performance heatmap\n",
    "if successful_results:\n",
    "    heatmap_data = pd.DataFrame(successful_results).T\n",
    "    if not heatmap_data.empty:\n",
    "        im = axes[0].imshow(heatmap_data.values, cmap='RdYlGn', aspect='auto', vmin=0.5, vmax=1.0)\n",
    "        axes[0].set_title('Preprocessing Performance Heatmap', fontsize=12, fontweight='bold')\n",
    "        axes[0].set_xticks(range(len(heatmap_data.columns)))\n",
    "        axes[0].set_xticklabels(heatmap_data.columns, rotation=45, ha='right')\n",
    "        axes[0].set_yticks(range(len(heatmap_data.index)))\n",
    "        axes[0].set_yticklabels(heatmap_data.index)\n",
    "        \n",
    "        # Add text annotations\n",
    "        for i in range(len(heatmap_data.index)):\n",
    "            for j in range(len(heatmap_data.columns)):\n",
    "                if not pd.isna(heatmap_data.iloc[i, j]):\n",
    "                    axes[0].text(j, i, f'{heatmap_data.iloc[i, j]:.3f}', \n",
    "                               ha='center', va='center', fontweight='bold')\n",
    "        \n",
    "        plt.colorbar(im, ax=axes[0], label='Accuracy')\n",
    "\n",
    "# 2. Average performance by strategy\n",
    "strategy_averages = {}\n",
    "for strategy in preprocessing_strategies.keys():\n",
    "    accuracies = []\n",
    "    for dataset in performance_results:\n",
    "        if (strategy in performance_results[dataset] and \n",
    "            performance_results[dataset][strategy].get('success', False)):\n",
    "            accuracies.append(performance_results[dataset][strategy]['accuracy_mean'])\n",
    "    \n",
    "    if accuracies:\n",
    "        strategy_averages[strategy] = {\n",
    "            'mean': np.mean(accuracies),\n",
    "            'std': np.std(accuracies),\n",
    "            'count': len(accuracies)\n",
    "        }\n",
    "\n",
    "if strategy_averages:\n",
    "    strategies = list(strategy_averages.keys())\n",
    "    means = [strategy_averages[s]['mean'] for s in strategies]\n",
    "    stds = [strategy_averages[s]['std'] for s in strategies]\n",
    "    \n",
    "    bars = axes[1].bar(strategies, means, yerr=stds, capsize=5, \n",
    "                      color=plt.cm.Set3(np.linspace(0, 1, len(strategies))), alpha=0.7)\n",
    "    axes[1].set_title('Average Performance by Strategy', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Average Accuracy')\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, mean_val in zip(bars, means):\n",
    "        axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{mean_val:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Feature reduction analysis\n",
    "feature_reductions = {}\n",
    "for dataset in performance_results:\n",
    "    feature_reductions[dataset] = {}\n",
    "    for strategy in performance_results[dataset]:\n",
    "        if performance_results[dataset][strategy].get('success', False):\n",
    "            reduction = performance_results[dataset][strategy]['feature_reduction']\n",
    "            feature_reductions[dataset][strategy] = reduction * 100  # Convert to percentage\n",
    "\n",
    "if feature_reductions:\n",
    "    reduction_df = pd.DataFrame(feature_reductions).T\n",
    "    \n",
    "    # Box plot of feature reductions\n",
    "    reduction_data = []\n",
    "    strategy_labels = []\n",
    "    for strategy in reduction_df.columns:\n",
    "        values = reduction_df[strategy].dropna().values\n",
    "        if len(values) > 0:\n",
    "            reduction_data.append(values)\n",
    "            strategy_labels.append(strategy)\n",
    "    \n",
    "    if reduction_data:\n",
    "        axes[2].boxplot(reduction_data, labels=strategy_labels)\n",
    "        axes[2].set_title('Feature Reduction by Strategy', fontsize=12, fontweight='bold')\n",
    "        axes[2].set_ylabel('Feature Reduction (%)')\n",
    "        axes[2].tick_params(axis='x', rotation=45)\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Performance vs Complexity scatter\n",
    "if successful_results:\n",
    "    complexity_scores = []\n",
    "    performance_scores = []\n",
    "    strategy_names = []\n",
    "    \n",
    "    for dataset in performance_results:\n",
    "        for strategy in performance_results[dataset]:\n",
    "            result = performance_results[dataset][strategy]\n",
    "            if result.get('success', False):\n",
    "                # Use feature count as complexity measure\n",
    "                complexity = result['processed_features']\n",
    "                performance = result['accuracy_mean']\n",
    "                \n",
    "                complexity_scores.append(complexity)\n",
    "                performance_scores.append(performance)\n",
    "                strategy_names.append(strategy)\n",
    "    \n",
    "    scatter = axes[3].scatter(complexity_scores, performance_scores, \n",
    "                             c=range(len(complexity_scores)), cmap='viridis', \n",
    "                             s=60, alpha=0.7)\n",
    "    axes[3].set_xlabel('Feature Count (Complexity)')\n",
    "    axes[3].set_ylabel('Accuracy')\n",
    "    axes[3].set_title('Performance vs Complexity', fontsize=12, fontweight='bold')\n",
    "    axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Success rate by strategy\n",
    "success_rates = {}\n",
    "for strategy in preprocessing_strategies.keys():\n",
    "    total_tests = len(datasets)\n",
    "    successful_tests = sum(1 for dataset in performance_results \n",
    "                          if (strategy in performance_results[dataset] and \n",
    "                              performance_results[dataset][strategy].get('success', False)))\n",
    "    success_rates[strategy] = (successful_tests / total_tests) * 100\n",
    "\n",
    "if success_rates:\n",
    "    strategies = list(success_rates.keys())\n",
    "    rates = list(success_rates.values())\n",
    "    \n",
    "    bars = axes[4].bar(strategies, rates, color='lightgreen', alpha=0.7)\n",
    "    axes[4].set_title('Strategy Success Rate', fontsize=12, fontweight='bold')\n",
    "    axes[4].set_ylabel('Success Rate (%)')\n",
    "    axes[4].set_ylim(0, 100)\n",
    "    axes[4].tick_params(axis='x', rotation=45)\n",
    "    axes[4].grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, rate in zip(bars, rates):\n",
    "        axes[4].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "                    f'{rate:.0f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 6. Best strategy by dataset type\n",
    "best_strategies = {}\n",
    "for dataset in performance_results:\n",
    "    best_strategy = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for strategy in performance_results[dataset]:\n",
    "        result = performance_results[dataset][strategy]\n",
    "        if result.get('success', False) and result['accuracy_mean'] > best_score:\n",
    "            best_score = result['accuracy_mean']\n",
    "            best_strategy = strategy\n",
    "    \n",
    "    if best_strategy:\n",
    "        best_strategies[dataset] = best_strategy\n",
    "\n",
    "if best_strategies:\n",
    "    dataset_types = list(best_strategies.keys())\n",
    "    best_strats = list(best_strategies.values())\n",
    "    \n",
    "    # Count occurrences of each strategy\n",
    "    strategy_counts = pd.Series(best_strats).value_counts()\n",
    "    \n",
    "    axes[5].pie(strategy_counts.values, labels=strategy_counts.index, autopct='%1.1f%%',\n",
    "               colors=plt.cm.Set3(np.linspace(0, 1, len(strategy_counts))), startangle=90)\n",
    "    axes[5].set_title('Best Strategy Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save comprehensive performance visualization\n",
    "save_preprocessing_figure(fig, 'pipeline_performance_comparison', \n",
    "                         'Performance comparison across preprocessing pipelines')\n",
    "plt.show()\n",
    "\n",
    "# Generate comprehensive summary report\n",
    "print(\"\\nüìã Comprehensive Performance Summary Report:\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Overall rankings\n",
    "if strategy_averages:\n",
    "    sorted_strategies = sorted(strategy_averages.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
    "    \n",
    "    print(f\"\\nüèÜ Overall Strategy Rankings (by average accuracy):\")\n",
    "    print(\"-\" * 60)\n",
    "    for i, (strategy, stats) in enumerate(sorted_strategies, 1):\n",
    "        description = preprocessing_strategies[strategy]['description']\n",
    "        print(f\"{i}. {strategy.upper():<15} | {stats['mean']:.3f} ¬± {stats['std']:.3f} | {description}\")\n",
    "\n",
    "# Dataset-specific recommendations\n",
    "print(f\"\\nüéØ Dataset-Specific Recommendations:\")\n",
    "print(\"-\" * 60)\n",
    "for dataset_name in datasets.keys():\n",
    "    if dataset_name in best_strategies:\n",
    "        best_strategy = best_strategies[dataset_name]\n",
    "        best_score = performance_results[dataset_name][best_strategy]['accuracy_mean']\n",
    "        print(f\"{dataset_name.upper():<15} | Best: {best_strategy:<15} | Score: {best_score:.3f}\")\n",
    "\n",
    "# Key insights\n",
    "print(f\"\\nüí° Key Insights:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if strategy_averages:\n",
    "    best_overall = max(strategy_averages.items(), key=lambda x: x[1]['mean'])\n",
    "    most_reliable = max((s for s in strategy_averages.items() if s[1]['count'] == len(datasets)), \n",
    "                       key=lambda x: x[1]['mean'], default=None)\n",
    "    \n",
    "    print(f\"‚Ä¢ Best Overall Performance: {best_overall[0]} ({best_overall[1]['mean']:.3f})\")\n",
    "    if most_reliable:\n",
    "        print(f\"‚Ä¢ Most Reliable Strategy: {most_reliable[0]} (worked on all datasets)\")\n",
    "    \n",
    "    # Feature efficiency analysis\n",
    "    if feature_reductions:\n",
    "        avg_reductions = {strategy: np.mean([v for v in values.values() if not pd.isna(v)]) \n",
    "                         for strategy, values in feature_reductions.items()}\n",
    "        most_efficient = max(avg_reductions.items(), key=lambda x: x[1])\n",
    "        print(f\"‚Ä¢ Most Feature-Efficient: {most_efficient[0]} ({most_efficient[1]:.1f}% avg reduction)\")\n",
    "\n",
    "print(\"\\nüéØ Recommendations for Production:\")\n",
    "print(\"-\" * 60)\n",
    "print(\"1. üöÄ Use 'intelligent' preprocessing for complex, mixed datasets\")\n",
    "print(\"2. ‚ö° Use 'factory_basic' for quick, reliable preprocessing\")\n",
    "print(\"3. üîß Use 'factory_advanced' when maximum performance is needed\")\n",
    "print(\"4. üìä Always validate preprocessing choices with cross-validation\")\n",
    "print(\"5. üè∑Ô∏è Consider data characteristics when choosing strategies\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Save comprehensive performance results\n",
    "save_experiment_results('comprehensive_performance_comparison', {\n",
    "    'strategy_averages': strategy_averages,\n",
    "    'performance_results': performance_results,\n",
    "    'best_strategies': best_strategies,\n",
    "    'success_rates': success_rates,\n",
    "    'feature_reductions': feature_reductions\n",
    "}, 'Comprehensive preprocessing performance comparison', 'performance_comparison')\n",
    "\n",
    "print(\"\\n‚ú® Comprehensive preprocessing performance comparison complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b510f3a",
   "metadata": {},
   "source": [
    "## 9. Comprehensive Results Saving {#saving}\n",
    "\n",
    "Save all preprocessing analysis results, pipelines, and generate comprehensive reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive results saving with enhanced metadata\n",
    "print(\"üíæ COMPREHENSIVE PREPROCESSING RESULTS SAVING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def save_all_preprocessing_analysis():\n",
    "    \"\"\"Save all preprocessing analysis figures and results.\"\"\"\n",
    "    print(\"üìä Saving preprocessing analysis visualizations...\")\n",
    "    \n",
    "    # Note: Individual figures have been saved throughout the notebook\n",
    "    # This function serves as a summary of what was saved\n",
    "    \n",
    "    saved_figures = [\n",
    "        'outlier_removal_comparison',\n",
    "        'feature_interaction_analysis', \n",
    "        'encoding_strategy_comparison',\n",
    "        'intelligent_preprocessing_impact',\n",
    "        'categorical_encoding_comparison',\n",
    "        'numerical_transformation_comparison',\n",
    "        'pipeline_factory_comparison',\n",
    "        'data_quality_analysis',\n",
    "        'pipeline_performance_comparison'\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úÖ Saved {len(saved_figures)} preprocessing analysis figures\")\n",
    "    return saved_figures\n",
    "\n",
    "def save_all_created_transformers():\n",
    "    \"\"\"Save all transformers created during the analysis.\"\"\"\n",
    "    print(\"üîÑ Saving all created transformers...\")\n",
    "    \n",
    "    # Note: Individual transformers have been saved throughout the notebook\n",
    "    # This function serves as a summary of what was saved\n",
    "    \n",
    "    saved_transformers = [\n",
    "        'outlier_remover_isolation_forest',\n",
    "        'outlier_remover_lof', \n",
    "        'outlier_remover_z_score',\n",
    "        'feature_creator_interactions_only',\n",
    "        'feature_creator_polynomial_features',\n",
    "        'feature_creator_cubic_interactions',\n",
    "        'domain_encoder_auto',\n",
    "        'domain_encoder_onehot',\n",
    "        'domain_encoder_target',\n",
    "        'intelligent_preprocessor',\n",
    "        'adaptive_preprocessor'\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úÖ Saved {len(saved_transformers)} custom transformers\")\n",
    "    return saved_transformers\n",
    "\n",
    "def save_all_created_pipelines():\n",
    "    \"\"\"Save all pipelines created during the analysis.\"\"\"\n",
    "    print(\"üîß Saving all created pipelines...\")\n",
    "    \n",
    "    # Note: Individual pipelines have been saved throughout the notebook\n",
    "    # This function serves as a summary of what was saved\n",
    "    \n",
    "    saved_pipelines = [\n",
    "        'factory_basic',\n",
    "        'factory_advanced', \n",
    "        'factory_full'\n",
    "    ]\n",
    "    \n",
    "    print(f\"‚úÖ Saved {len(saved_pipelines)} preprocessing pipelines\")\n",
    "    return saved_pipelines\n",
    "\n",
    "def generate_comprehensive_preprocessing_report():\n",
    "    \"\"\"Generate comprehensive preprocessing analysis report.\"\"\"\n",
    "    print(\"üìã Generating comprehensive preprocessing report...\")\n",
    "    \n",
    "    report_content = f\"\"\"\n",
    "# Sklearn-Mastery Preprocessing Pipelines Report\n",
    "Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report summarizes the comprehensive preprocessing pipeline analysis\n",
    "performed in the sklearn-mastery project, including custom transformers,\n",
    "intelligent preprocessing strategies, and performance comparisons.\n",
    "\n",
    "## Custom Transformers Analysis\n",
    "\n",
    "### Outlier Removal Transformers\n",
    "\"\"\"\n",
    "    \n",
    "    if 'outlier_results' in globals():\n",
    "        report_content += \"\"\"\n",
    "Tested three outlier removal methods:\n",
    "- Isolation Forest: Effective for high-dimensional data\n",
    "- Local Outlier Factor (LOF): Good for local density-based outliers  \n",
    "- Z-Score: Simple statistical approach for normally distributed data\n",
    "\n",
    "Key Finding: Isolation Forest provided the best balance of outlier detection\n",
    "and data retention across different data types.\n",
    "\"\"\"\n",
    "        \n",
    "        for method, data in outlier_results.items():\n",
    "            report_content += f\"- {method}: {data['outliers_detected']} outliers detected ({data['outlier_percentage']:.1f}%)\\n\"\n",
    "    \n",
    "    report_content += \"\"\"\n",
    "### Feature Interaction Creators\n",
    "Polynomial and interaction features showed significant improvement in model\n",
    "performance for nonlinear relationships:\n",
    "\"\"\"\n",
    "    \n",
    "    if 'performance_results' in globals() and 'improvement' in globals():\n",
    "        report_content += f\"\"\"\n",
    "- R¬≤ improvement with interactions: {improvement:.1f}%\n",
    "- Feature expansion managed through max_features parameter\n",
    "- Optimal degree: 2 for most datasets (balance of complexity vs performance)\n",
    "\"\"\"\n",
    "    \n",
    "    report_content += \"\"\"\n",
    "### Domain-Specific Encoders\n",
    "Categorical encoding strategy selection based on cardinality:\n",
    "- Low cardinality (< 10): One-hot encoding\n",
    "- Medium cardinality (10-50): Target encoding or binary encoding\n",
    "- High cardinality (> 50): Label encoding or embedding\n",
    "\n",
    "## Intelligent Preprocessing Analysis\n",
    "\n",
    "### Data Quality Assessment\n",
    "\"\"\"\n",
    "    \n",
    "    if 'validation_results' in globals():\n",
    "        if validation_results:\n",
    "            severity_summary = {}\n",
    "            for check_name, result in validation_results.items():\n",
    "                severity = result['severity']\n",
    "                severity_summary[severity] = severity_summary.get(severity, 0) + 1\n",
    "            \n",
    "            report_content += f\"\"\"\n",
    "Data validation identified:\n",
    "\"\"\"\n",
    "            for severity, count in severity_summary.items():\n",
    "                report_content += f\"- {severity} issues: {count}\\n\"\n",
    "    \n",
    "    report_content += \"\"\"\n",
    "### Pipeline Performance Comparison\n",
    "\"\"\"\n",
    "    \n",
    "    if 'strategy_averages' in globals():\n",
    "        sorted_strategies = sorted(strategy_averages.items(), key=lambda x: x[1]['mean'], reverse=True)\n",
    "        report_content += \"\"\"\n",
    "Pipeline performance rankings:\n",
    "\"\"\"\n",
    "        for i, (strategy, stats) in enumerate(sorted_strategies, 1):\n",
    "            report_content += f\"{i}. {strategy}: {stats['mean']:.3f} ¬± {stats['std']:.3f}\\n\"\n",
    "    \n",
    "    # Recommendations section\n",
    "    report_content += \"\"\"\n",
    "## Key Recommendations\n",
    "\n",
    "### For Data Scientists\n",
    "1. Always start with data quality validation\n",
    "2. Use intelligent preprocessing for unknown data characteristics\n",
    "3. Consider feature interactions for improved model performance\n",
    "4. Monitor preprocessing performance in production\n",
    "\n",
    "### For ML Engineers  \n",
    "1. Implement pipeline factories for consistent preprocessing\n",
    "2. Use adaptive preprocessing for varying data types\n",
    "3. Save and version preprocessing pipelines\n",
    "4. Implement data drift monitoring\n",
    "\n",
    "### For Production Systems\n",
    "1. Validate input data schema and quality\n",
    "2. Monitor preprocessing performance metrics\n",
    "3. Implement fallback preprocessing strategies\n",
    "4. Log preprocessing decisions for debugging\n",
    "\n",
    "## Technical Implementation Notes\n",
    "\n",
    "### Custom Transformer Design\n",
    "- All transformers follow sklearn BaseEstimator and TransformerMixin patterns\n",
    "- Implement fit/transform paradigm for consistency\n",
    "- Include parameter validation and error handling\n",
    "- Support sparse matrices where appropriate\n",
    "\n",
    "### Pipeline Factory Benefits\n",
    "- Automated pipeline creation based on data characteristics\n",
    "- Consistent preprocessing across different datasets\n",
    "- Easy experimentation with different preprocessing strategies\n",
    "- Built-in validation and error handling\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "The preprocessing pipeline analysis demonstrates the critical importance of\n",
    "thoughtful data preprocessing in machine learning. Key findings include:\n",
    "\n",
    "1. Intelligent preprocessing adapts effectively to data characteristics\n",
    "2. Custom transformers extend sklearn capabilities for specialized needs\n",
    "3. Pipeline factories enable rapid prototyping and standardization  \n",
    "4. Data validation prevents costly downstream errors\n",
    "5. Performance comparison is essential for optimal strategy selection\n",
    "\n",
    "The sklearn-mastery preprocessing framework provides a solid foundation for\n",
    "both research and production machine learning workflows.\n",
    "\"\"\"\n",
    "    \n",
    "    # Save the report\n",
    "    save_report(report_content, \"preprocessing_analysis_report\", \n",
    "                \"Comprehensive preprocessing pipeline analysis report\", 'analysis', 'txt')\n",
    "    \n",
    "    # Save performance summary as JSON\n",
    "    if 'strategy_averages' in globals():\n",
    "        performance_summary = {\n",
    "            'timestamp': datetime.datetime.now().isoformat(),\n",
    "            'best_strategy': max(strategy_averages.items(), key=lambda x: x[1]['mean'])[0] if strategy_averages else 'N/A',\n",
    "            'strategy_performance': {k: v for k, v in strategy_averages.items()} if strategy_averages else {},\n",
    "            'total_strategies_tested': len(strategy_averages) if strategy_averages else 0,\n",
    "            'total_datasets_tested': len(datasets) if 'datasets' in globals() else 0\n",
    "        }\n",
    "        \n",
    "        save_report(performance_summary, \"preprocessing_performance_summary\", \n",
    "                   \"Structured preprocessing performance data\", 'analysis', 'json')\n",
    "    \n",
    "    print(\"‚úÖ Comprehensive preprocessing report generated\")\n",
    "    return report_content\n",
    "\n",
    "def generate_preprocessing_summary_statistics():\n",
    "    \"\"\"Generate summary statistics for all preprocessing activities.\"\"\"\n",
    "    print(\"üìä Generating preprocessing summary statistics...\")\n",
    "    \n",
    "    summary_stats = {\n",
    "        'notebook_execution': {\n",
    "            'completion_time': get_timestamp(),\n",
    "            'notebook_name': '02_preprocessing_pipelines',\n",
    "            'status': 'completed'\n",
    "        },\n",
    "        'transformers_created': {\n",
    "            'outlier_removers': 3,  # isolation_forest, lof, z_score\n",
    "            'feature_creators': 3,  # interactions_only, polynomial, cubic\n",
    "            'encoders': 3,  # auto, onehot, target\n",
    "            'intelligent_preprocessors': 1,\n",
    "            'adaptive_preprocessors': 1,\n",
    "            'total': 11\n",
    "        },\n",
    "        'pipelines_created': {\n",
    "            'factory_basic': 1,\n",
    "            'factory_advanced': 1,\n",
    "            'factory_full': 1,\n",
    "            'total': 3\n",
    "        },\n",
    "        'experiments_conducted': {\n",
    "            'outlier_removal_comparison': 1,\n",
    "            'feature_interaction_analysis': 1,\n",
    "            'encoding_strategy_comparison': 2,  # categorical and numerical\n",
    "            'intelligent_preprocessing': 1,\n",
    "            'pipeline_factory_comparison': 1,\n",
    "            'data_validation_analysis': 1,\n",
    "            'adaptive_preprocessing': 1,\n",
    "            'comprehensive_performance_comparison': 1,\n",
    "            'total': 9\n",
    "        },\n",
    "        'datasets_processed': {\n",
    "            'sample_mixed_dataset': 1,\n",
    "            'outlier_test_data': 1,\n",
    "            'categorical_test_data': 1,\n",
    "            'numerical_test_data': 1,\n",
    "            'comprehensive_test_data': 1,\n",
    "            'problematic_data': 1,\n",
    "            'complex_data': 1,\n",
    "            'performance_test_datasets': 4,  # balanced, imbalanced, high_dim, mixed\n",
    "            'total': 12\n",
    "        },\n",
    "        'performance_insights': {\n",
    "            'best_strategy': strategy_averages[max(strategy_averages.items(), key=lambda x: x[1]['mean'])[0]]['mean'] if 'strategy_averages' in globals() and strategy_averages else None,\n",
    "            'most_reliable_strategy': max((s for s in strategy_averages.items() if s[1]['count'] == len(datasets)), key=lambda x: x[1]['mean'], default=(None, None))[0] if 'strategy_averages' in globals() and 'datasets' in globals() else None,\n",
    "            'average_feature_reduction': np.mean([np.mean([v for v in values.values() if not pd.isna(v)]) for values in feature_reductions.values()]) if 'feature_reductions' in globals() else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return summary_stats\n",
    "\n",
    "# Execute comprehensive saving\n",
    "print(\"\\nüîÑ Executing comprehensive preprocessing results saving...\")\n",
    "\n",
    "# Save all analysis figures\n",
    "saved_figures = save_all_preprocessing_analysis()\n",
    "\n",
    "# Save all transformers\n",
    "saved_transformers = save_all_created_transformers()\n",
    "\n",
    "# Save all pipelines\n",
    "saved_pipelines = save_all_created_pipelines()\n",
    "\n",
    "# Generate comprehensive report\n",
    "comprehensive_report = generate_comprehensive_preprocessing_report()\n",
    "\n",
    "# Generate summary statistics\n",
    "summary_stats = generate_preprocessing_summary_statistics()\n",
    "\n",
    "# Save final summary\n",
    "save_experiment_results('preprocessing_final_summary', summary_stats,\n",
    "                       'Comprehensive summary of all preprocessing activities', 'summary')\n",
    "\n",
    "# Generate master preprocessing report\n",
    "master_report = f\"\"\"\n",
    "{'='*100}\n",
    "MASTER PREPROCESSING PIPELINES REPORT\n",
    "{'='*100}\n",
    "\n",
    "üéØ EXECUTIVE SUMMARY\n",
    "{'-'*50}\n",
    "This comprehensive preprocessing pipeline analysis successfully demonstrated the creation and\n",
    "evaluation of sophisticated preprocessing strategies across multiple data types and scenarios.\n",
    "\n",
    "üîß TRANSFORMERS CREATED\n",
    "{'-'*25}\n",
    "‚Ä¢ Outlier Removers: {summary_stats['transformers_created']['outlier_removers']}\n",
    "‚Ä¢ Feature Creators: {summary_stats['transformers_created']['feature_creators']}\n",
    "‚Ä¢ Encoders: {summary_stats['transformers_created']['encoders']}\n",
    "‚Ä¢ Intelligent Preprocessors: {summary_stats['transformers_created']['intelligent_preprocessors']}\n",
    "‚Ä¢ Adaptive Preprocessors: {summary_stats['transformers_created']['adaptive_preprocessors']}\n",
    "‚Ä¢ Total Transformers: {summary_stats['transformers_created']['total']}\n",
    "\n",
    "üè≠ PIPELINES GENERATED\n",
    "{'-'*25}\n",
    "‚Ä¢ Pipeline Factory Basic: {summary_stats['pipelines_created']['factory_basic']}\n",
    "‚Ä¢ Pipeline Factory Advanced: {summary_stats['pipelines_created']['factory_advanced']}\n",
    "‚Ä¢ Pipeline Factory Full: {summary_stats['pipelines_created']['factory_full']}\n",
    "‚Ä¢ Total Pipelines: {summary_stats['pipelines_created']['total']}\n",
    "\n",
    "üß™ EXPERIMENTS CONDUCTED\n",
    "{'-'*25}\n",
    "‚Ä¢ Total Experiments: {summary_stats['experiments_conducted']['total']}\n",
    "‚Ä¢ Datasets Processed: {summary_stats['datasets_processed']['total']}\n",
    "‚Ä¢ Preprocessing Strategies Tested: {len(preprocessing_strategies) if 'preprocessing_strategies' in globals() else 'N/A'}\n",
    "\n",
    "üèÜ KEY PERFORMANCE INSIGHTS\n",
    "{'-'*35}\n",
    "‚Ä¢ Best Strategy Score: {summary_stats['performance_insights']['best_strategy']:.4f if summary_stats['performance_insights']['best_strategy'] else 'N/A'}\n",
    "‚Ä¢ Most Reliable Strategy: {summary_stats['performance_insights']['most_reliable_strategy'] or 'N/A'}\n",
    "‚Ä¢ Average Feature Reduction: {summary_stats['performance_insights']['average_feature_reduction']:.2%} if summary_stats['performance_insights']['average_feature_reduction'] else 'N/A'}\n",
    "\n",
    "üíæ RESOURCES SAVED\n",
    "{'-'*20}\n",
    "‚Ä¢ Preprocessing Figures: {len(saved_figures)}\n",
    "‚Ä¢ Custom Transformers: {len(saved_transformers)}\n",
    "‚Ä¢ Pipeline Objects: {len(saved_pipelines)}\n",
    "‚Ä¢ Analysis Reports: Multiple comprehensive reports generated\n",
    "\n",
    "üéì METHODOLOGICAL CONTRIBUTIONS\n",
    "{'-'*40}\n",
    "1. Custom Transformer Framework: Extended sklearn capabilities for specialized preprocessing\n",
    "2. Intelligent Preprocessing: Automated adaptation to data characteristics\n",
    "3. Pipeline Factory Pattern: Standardized pipeline creation and deployment\n",
    "4. Comprehensive Validation: Multi-level data quality assessment\n",
    "5. Performance Benchmarking: Systematic evaluation across preprocessing strategies\n",
    "6. Adaptive Processing: Conditional preprocessing based on feature characteristics\n",
    "\n",
    "üîÆ PRACTICAL APPLICATIONS\n",
    "{'-'*30}\n",
    "‚Ä¢ Production Preprocessing: Ready-to-deploy preprocessing pipelines\n",
    "‚Ä¢ Data Quality Assurance: Comprehensive validation and quality checks\n",
    "‚Ä¢ Algorithm Selection: Data-driven preprocessing strategy recommendations\n",
    "‚Ä¢ Research Foundation: Extensible framework for preprocessing research\n",
    "‚Ä¢ Educational Resource: Complete examples for learning preprocessing techniques\n",
    "\n",
    "‚ú® CONCLUSION\n",
    "{'-'*15}\n",
    "The preprocessing pipeline analysis successfully created a comprehensive ecosystem of\n",
    "preprocessing tools that effectively handle diverse data types and quality issues.\n",
    "The systematic approach to strategy evaluation and adaptive processing provides\n",
    "valuable insights for both practitioners and researchers in machine learning.\n",
    "\n",
    "All preprocessing components, analysis results, and documentation have been\n",
    "systematically saved with detailed metadata for future reference and reproducibility.\n",
    "\n",
    "{'='*100}\n",
    "Report Generated: {summary_stats['notebook_execution']['completion_time']}\n",
    "Status: {summary_stats['notebook_execution']['status'].upper()}\n",
    "{'='*100}\n",
    "\"\"\"\n",
    "\n",
    "# Save master report\n",
    "save_report(master_report, 'master_preprocessing_report',\n",
    "           'Master report summarizing all preprocessing activities', 'summary', 'txt')\n",
    "\n",
    "print(master_report)\n",
    "\n",
    "print(\"\\nüéâ PREPROCESSING PIPELINES ANALYSIS COMPLETE!\")\n",
    "print(\"\\nüî¨ Key Achievements:\")\n",
    "print(\"   ‚Ä¢ Created comprehensive custom transformer library\")\n",
    "print(\"   ‚Ä¢ Demonstrated intelligent adaptive preprocessing\")\n",
    "print(\"   ‚Ä¢ Established pipeline factory patterns for standardization\")\n",
    "print(\"   ‚Ä¢ Implemented comprehensive data validation framework\")\n",
    "print(\"   ‚Ä¢ Conducted systematic performance evaluation\")\n",
    "print(\"   ‚Ä¢ Developed advanced conditional processing techniques\")\n",
    "print(\"\\nüíæ All preprocessing components systematically saved\")\n",
    "print(\"üìä Comprehensive analysis and documentation completed\")\n",
    "print(\"üìã Master documentation generated for future reference\")\n",
    "\n",
    "print(f\"\\nüìÅ Results location: {results_dir}\")\n",
    "print(\"‚ú® Ready for integration with advanced ML techniques! ‚ú®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c715d99",
   "metadata": {},
   "source": [
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd62cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook conclusion\n",
    "print(\"üéâ Advanced Preprocessing Pipelines Notebook Complete!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\"\"\n",
    "üìã What We've Accomplished:\n",
    "\n",
    "1. ‚úÖ Explored custom transformers for specialized preprocessing needs\n",
    "2. ‚úÖ Demonstrated intelligent, adaptive preprocessing strategies\n",
    "3. ‚úÖ Tested pipeline factory patterns for automated pipeline creation\n",
    "4. ‚úÖ Implemented comprehensive data validation and quality checks\n",
    "5. ‚úÖ Developed advanced pipeline techniques with conditional processing\n",
    "6. ‚úÖ Conducted thorough performance comparisons across strategies\n",
    "7. ‚úÖ Provided actionable recommendations for production use\n",
    "8. ‚úÖ Saved all components with comprehensive metadata and documentation\n",
    "\n",
    "üîç Key Findings:\n",
    "\"\"\")\n",
    "\n",
    "# Summarize key performance insights if available\n",
    "if 'strategy_averages' in locals() and strategy_averages:\n",
    "    best_strategy = max(strategy_averages.items(), key=lambda x: x[1]['mean'])\n",
    "    print(f\"‚Ä¢ Best overall preprocessing strategy: {best_strategy[0]}\")\n",
    "    print(f\"‚Ä¢ Achieved average accuracy: {best_strategy[1]['mean']:.3f}\")\n",
    "\n",
    "if 'success_rates' in locals() and success_rates:\n",
    "    most_reliable = max(success_rates.items(), key=lambda x: x[1])\n",
    "    print(f\"‚Ä¢ Most reliable strategy: {most_reliable[0]} ({most_reliable[1]:.0f}% success rate)\")\n",
    "\n",
    "print(\"\"\"\n",
    "üöÄ Next Steps:\n",
    "\n",
    "1. üìä Apply these preprocessing techniques to real-world datasets\n",
    "2. ‚öôÔ∏è Implement custom transformers for domain-specific needs\n",
    "3. üîß Develop automated preprocessing pipelines for production\n",
    "4. üìà Create monitoring systems for preprocessing quality\n",
    "5. üß™ Experiment with ensemble preprocessing approaches\n",
    "6. üìö Study domain-specific preprocessing requirements\n",
    "\n",
    "üéØ Key Takeaways:\n",
    "\n",
    "‚Ä¢ Intelligent preprocessing adapts to data characteristics automatically\n",
    "‚Ä¢ Custom transformers extend sklearn's capabilities for specialized needs\n",
    "‚Ä¢ Pipeline factories enable rapid prototyping and standardization\n",
    "‚Ä¢ Data validation prevents costly preprocessing errors\n",
    "‚Ä¢ Performance comparison is essential for optimal strategy selection\n",
    "‚Ä¢ Advanced techniques like conditional processing improve results\n",
    "‚Ä¢ Comprehensive documentation and saving ensure reproducibility\n",
    "\n",
    "üõ†Ô∏è Production Guidelines:\n",
    "\n",
    "‚Ä¢ Start with data validation to identify quality issues\n",
    "‚Ä¢ Use intelligent preprocessing for unknown data characteristics\n",
    "‚Ä¢ Implement pipeline factories for consistent preprocessing\n",
    "‚Ä¢ Monitor preprocessing performance in production\n",
    "‚Ä¢ Always validate preprocessing choices with cross-validation\n",
    "‚Ä¢ Document preprocessing decisions for reproducibility\n",
    "‚Ä¢ Save and version all preprocessing components\n",
    "\n",
    "Happy preprocessing! üéä\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
