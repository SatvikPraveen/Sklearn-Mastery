# File: examples/real_world_scenarios/business_analytics/sales_forecasting.py
# Location: examples/real_world_scenarios/business_analytics/sales_forecasting.py

"""
Sales Forecasting System - Real-World ML Pipeline Example

Business Problem:
Predict future sales to optimize inventory management, resource allocation,
and business planning across different time horizons.

Dataset: Time series sales data with external factors (synthetic)
Target: Regression (sales amount prediction)
Business Impact: 25% reduction in inventory costs, 18% improvement in planning accuracy
Techniques: Time series analysis, feature engineering, ensemble forecasting

Industry Applications:
- Retail and e-commerce
- Manufacturing
- FMCG (Fast-Moving Consumer Goods)
- Automotive
- Technology products
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, Tuple, Any, List
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Framework imports
from src.data.generators import DataGenerator
from src.models.supervised.regression import RegressionModels
from src.models.ensemble.methods import EnsembleMethods
from src.evaluation.metrics import ModelEvaluator

# Scenario-specific imports
from ..utilities.data_loaders import DataLoader
from ..utilities.visualization_helpers import BusinessVisualizer
from ..utilities.evaluation_helpers import BusinessMetricsCalculator

class SalesForecastingSystem:
    """Complete sales forecasting system pipeline."""
    
    def __init__(self, config: Dict[str, Any] = None):
        """Initialize sales forecasting system."""
        
        self.config = config or {
            'data_periods': 730,  # 2 years of daily data
            'forecast_horizon': 30,  # Forecast next 30 days
            'test_size': 0.2,
            'validation_periods': 60,  # Last 60 days for validation
            'random_state': 42,
            'algorithms': ['linear_regression', 'random_forest', 'gradient_boosting'],
            'seasonal_periods': [7, 30, 365],  # Weekly, monthly, yearly
            'business_params': {
                'inventory_cost_per_unit': 10,
                'stockout_cost_per_unit': 50,
                'holding_cost_rate': 0.02
            }
        }
        
        # Initialize components
        self.data_loader = DataLoader(random_state=self.config['random_state'])
        self.visualizer = BusinessVisualizer()
        self.business_calc = BusinessMetricsCalculator()
        self.model_evaluator = ModelPerformanceEvaluator()
        
        # Results storage
        self.forecast_results = {}
        self.seasonal_components = {}
        self.best_model = None
        
    def load_and_analyze_sales_data(self) -> Tuple[pd.DataFrame, pd.Series]:
        """Load and analyze time series sales data."""
        
        print("üîÑ Loading sales forecasting dataset...")
        X, y = self.data_loader.load_sales_forecasting_data(n_periods=self.config['data_periods'])
        
        print(f"üìä Dataset shape: {X.shape}")
        print(f"üìä Time period: {X['date'].min()} to {X['date'].max()}")
        print(f"üìä Average daily sales: ${y.mean():,.2f}")
        print(f"üìä Sales range: ${y.min():,.2f} - ${y.max():,.2f}")
        
        # Time series analysis
        print("\nüìà Time Series Analysis:")
        
        # Convert to time series
        ts_data = pd.DataFrame({'date': X['date'], 'sales': y})
        ts_data.set_index('date', inplace=True)
        
        # Basic statistics
        print(f"   Mean daily sales: ${ts_data['sales'].mean():,.2f}")
        print(f"   Sales volatility (std): ${ts_data['sales'].std():,.2f}")
        print(f"   Coefficient of variation: {ts_data['sales'].std()/ts_data['sales'].mean():.2f}")
        
        # Trend analysis
        ts_data['sales_7d_avg'] = ts_data['sales'].rolling(window=7).mean()
        ts_data['sales_30d_avg'] = ts_data['sales'].rolling(window=30).mean()
        
        # Growth rates
        ts_data['sales_growth_1d'] = ts_data['sales'].pct_change()
        ts_data['sales_growth_7d'] = ts_data['sales_7d_avg'].pct_change(7)
        
        print(f"   Average daily growth: {ts_data['sales_growth_1d'].mean()*100:.2f}%")
        print(f"   Average weekly growth: {ts_data['sales_growth_7d'].mean()*100:.2f}%")
        
        # Seasonality detection
        self.detect_seasonality(ts_data)
        
        # Store for analysis
        self.sales_data = ts_data
        self.X_raw = X
        self.y_raw = y
        
        return X, y
    
    def detect_seasonality(self, ts_data: pd.DataFrame) -> Dict[str, Any]:
        """Detect and analyze seasonal patterns in sales data."""
        
        print("\nüîç Analyzing seasonal patterns...")
        
        try:
            from scipy import stats
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            # Perform seasonal decomposition
            decomposition = seasonal_decompose(ts_data['sales'], model='additive', period=7)
            
            self.seasonal_components = {
                'trend': decomposition.trend,
                'seasonal': decomposition.seasonal,
                'residual': decomposition.resid
            }
            
            # Day of week patterns
            ts_data['day_of_week'] = ts_data.index.dayofweek
            dow_sales = ts_data.groupby('day_of_week')['sales'].mean()
            
            print("   Day of week sales pattern:")
            days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']
            for i, day in enumerate(days):
                print(f"     {day}: ${dow_sales[i]:,.0f} ({(dow_sales[i]/dow_sales.mean()-1)*100:+.1f}%)")
            
            # Monthly patterns
            ts_data['month'] = ts_data.index.month
            monthly_sales = ts_data.groupby('month')['sales'].mean()
            
            peak_month = monthly_sales.idxmax()
            low_month = monthly_sales.idxmin()
            seasonality_strength = (monthly_sales.max() - monthly_sales.min()) / monthly_sales.mean()
            
            print(f"   Monthly seasonality strength: {seasonality_strength:.2f}")
            print(f"   Peak month: {peak_month} (${monthly_sales[peak_month]:,.0f})")
            print(f"   Low month: {low_month} (${monthly_sales[low_month]:,.0f})")
            
        except ImportError:
            print("   Seasonal decomposition not available (statsmodels required)")
            self.seasonal_components = {}
    
    def engineer_forecasting_features(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:
        """Create time series forecasting features."""
        
        print("\nüõ†Ô∏è Engineering forecasting features...")
        
        # Create time series DataFrame
        ts_df = pd.DataFrame({
            'date': X['date'],
            'sales': y,
            'day_of_week': X['day_of_week'],
            'month': X['month'],
            'quarter': X['quarter'],
            'is_weekend': X['is_weekend'],
            'is_holiday': X['is_holiday'],
            'promotion': X['promotion'],
            'temperature': X['temperature']
        })
        
        ts_df = ts_df.sort_values('date').reset_index(drop=True)
        
        # 1. Lag features
        for lag in [1, 2, 3, 7, 14, 30]:
            ts_df[f'sales_lag_{lag}'] = ts_df['sales'].shift(lag)
        
        # 2. Rolling window statistics
        for window in [3, 7, 14, 30]:
            ts_df[f'sales_rolling_mean_{window}'] = ts_df['sales'].rolling(window=window).mean().shift(1)
            ts_df[f'sales_rolling_std_{window}'] = ts_df['sales'].rolling(window=window).std().shift(1)
            ts_df[f'sales_rolling_min_{window}'] = ts_df['sales'].rolling(window=window).min().shift(1)
            ts_df[f'sales_rolling_max_{window}'] = ts_df['sales'].rolling(window=window).max().shift(1)
        
        # 3. Exponential smoothing features
        for alpha in [0.1, 0.3, 0.7]:
            ts_df[f'sales_ema_{alpha}'] = ts_df['sales'].ewm(alpha=alpha).mean().shift(1)
        
        # 4. Trend and change features
        ts_df['sales_diff_1'] = ts_df['sales'].diff(1)
        ts_df['sales_diff_7'] = ts_df['sales'].diff(7)
        ts_df['sales_pct_change_1'] = ts_df['sales'].pct_change(1)
        ts_df['sales_pct_change_7'] = ts_df['sales'].pct_change(7)
        
        # 5. Calendar features
        ts_df['day_of_year'] = pd.to_datetime(ts_df['date']).dt.dayofyear
        ts_df['week_of_year'] = pd.to_datetime(ts_df['date']).dt.isocalendar().week
        ts_df['is_month_start'] = pd.to_datetime(ts_df['date']).dt.is_month_start.astype(int)
        ts_df['is_month_end'] = pd.to_datetime(ts_df['date']).dt.is_month_end.astype(int)
        ts_df['is_quarter_start'] = pd.to_datetime(ts_df['date']).dt.is_quarter_start.astype(int)
        ts_df['is_quarter_end'] = pd.to_datetime(ts_df['date']).dt.is_quarter_end.astype(int)
        
        # 6. Cyclical encoding for calendar features
        ts_df['day_of_week_sin'] = np.sin(2 * np.pi * ts_df['day_of_week'] / 7)
        ts_df['day_of_week_cos'] = np.cos(2 * np.pi * ts_df['day_of_week'] / 7)
        ts_df['month_sin'] = np.sin(2 * np.pi * ts_df['month'] / 12)
        ts_df['month_cos'] = np.cos(2 * np.pi * ts_df['month'] / 12)
        ts_df['day_of_year_sin'] = np.sin(2 * np.pi * ts_df['day_of_year'] / 365)
        ts_df['day_of_year_cos'] = np.cos(2 * np.pi * ts_df['day_of_year'] / 365)
        
        # 7. External factor interactions
        ts_df['temp_sales_interaction'] = ts_df['temperature'] * ts_df['sales_rolling_mean_7']
        ts_df['promotion_weekend_interaction'] = ts_df['promotion'] * ts_df['is_weekend']
        ts_df['holiday_temp_interaction'] = ts_df['is_holiday'] * ts_df['temperature']
        
        # 8. Volatility and stability measures
        ts_df['sales_volatility_7d'] = ts_df['sales_rolling_std_7'] / ts_df['sales_rolling_mean_7']
        ts_df['sales_stability_score'] = 1 / (1 + ts_df['sales_volatility_7d'])
        
        # Remove rows with NaN values (due to lags and rolling windows)
        ts_df = ts_df.dropna().reset_index(drop=True)
        
        # Prepare features and target
        feature_cols = [col for col in ts_df.columns if col not in ['date', 'sales']]
        X_processed = ts_df[feature_cols]
        y_processed = ts_df['sales']
        
        print(f"‚úÖ Created {len(feature_cols)} forecasting features")
        print(f"üìä Final dataset shape: {X_processed.shape}")
        print(f"üìä Data after NaN removal: {len(ts_df)} periods")
        
        self.ts_features = ts_df
        
        return X_processed, y_processed
    
    def create_time_series_splits(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, Tuple]:
        """Create time series train/validation/test splits."""
        
        print("\nüìÖ Creating time series splits...")
        
        n_samples = len(X)
        validation_size = self.config['validation_periods']
        test_size = int(n_samples * self.config['test_size'])
        
        # Time series split (no random shuffling)
        train_end = n_samples - validation_size - test_size
        val_end = n_samples - test_size
        
        # Training set
        X_train = X.iloc[:train_end]
        y_train = y.iloc[:train_end]
        
        # Validation set
        X_val = X.iloc[train_end:val_end]
        y_val = y.iloc[train_end:val_end]
        
        # Test set
        X_test = X.iloc[val_end:]
        y_test = y.iloc[val_end:]
        
        print(f"   Training set: {len(X_train)} periods")
        print(f"   Validation set: {len(X_val)} periods")
        print(f"   Test set: {len(X_test)} periods")
        
        if hasattr(self, 'ts_features'):
            train_dates = self.ts_features.iloc[:train_end]['date']
            val_dates = self.ts_features.iloc[train_end:val_end]['date']
            test_dates = self.ts_features.iloc[val_end:]['date']
            
            print(f"   Training period: {train_dates.min()} to {train_dates.max()}")
            print(f"   Validation period: {val_dates.min()} to {val_dates.max()}")
            print(f"   Test period: {test_dates.min()} to {test_dates.max()}")
        
        splits = {
            'train': (X_train, y_train),
            'validation': (X_val, y_val),
            'test': (X_test, y_test)
        }
        
        self.data_splits = splits
        return splits
    
    def train_forecasting_models(self, splits: Dict[str, Tuple]) -> Dict[str, Any]:
        """Train and evaluate forecasting models."""
        
        print("\nü§ñ Training forecasting models...")
        
        X_train, y_train = splits['train']
        X_val, y_val = splits['validation']
        X_test, y_test = splits['test']
        
        # Initialize models
        models = RegressionModels()
        ensemble = EnsembleMethods()
        
        # Configure models for time series
        algorithms_to_test = {
            'Linear Regression': models.get_linear_regression(),
            'Ridge Regression': models.get_ridge_regression(alpha=1.0),
            'Random Forest': models.get_random_forest_regression(
                n_estimators=200, 
                random_state=self.config['random_state']
            ),
            'Gradient Boosting': models.get_gradient_boosting_regression(
                n_estimators=200,
                learning_rate=0.1,
                random_state=self.config['random_state']
            )
        }
        
        # Add XGBoost if available
        try:
            algorithms_to_test['XGBoost'] = models.get_xgboost_regression(
                n_estimators=200,
                learning_rate=0.1,
                random_state=self.config['random_state']
            )
        except:
            print("   XGBoost not available, skipping...")
        
        # Train and evaluate models
        model_results = {}
        
        for name, model in algorithms_to_test.items():
            print(f"   Training {name}...")
            
            # Fit model
            model.fit(X_train, y_train)
            
            # Validate model
            val_pred = model.predict(X_val)
            val_performance = self.model_evaluator.evaluate_regression_model(
                model, X_val, y_val
            )
            
            # Test model
            test_pred = model.predict(X_test)
            test_performance = self.model_evaluator.evaluate_regression_model(
                model, X_test, y_test
            )
            
            # Calculate business impact
            business_impact = self.business_calc.calculate_sales_forecast_impact(
                y_test.values, test_pred, **self.config['business_params']
            )
            
            # Calculate forecast accuracy metrics
            forecast_metrics = self.calculate_forecast_accuracy(y_test, test_pred)
            
            model_results[name] = {
                'model': model,
                'validation_performance': val_performance,
                'test_performance': test_performance,
                'business_impact': business_impact,
                'forecast_metrics': forecast_metrics,
                'predictions': {
                    'validation': val_pred,
                    'test': test_pred
                }
            }
            
            print(f"      Validation RMSE: {val_performance['rmse']:,.2f}")
            print(f"      Test RMSE: {test_performance['rmse']:,.2f}")
            print(f"      Test MAPE: {test_performance['mape']:.2f}%")
            print(f"      Forecast Accuracy: {forecast_metrics['accuracy']:.1f}%")
        
        # Select best model based on validation performance
        best_model_name = min(model_results.keys(), 
                            key=lambda x: model_results[x]['validation_performance']['rmse'])
        
        self.best_model = model_results[best_model_name]['model']
        self.best_model_name = best_model_name
        
        print(f"\nüèÜ Best model: {best_model_name}")
        print(f"   Validation RMSE: {model_results[best_model_name]['validation_performance']['rmse']:,.2f}")
        print(f"   Test RMSE: {model_results[best_model_name]['test_performance']['rmse']:,.2f}")
        print(f"   Forecast Accuracy: {model_results[best_model_name]['forecast_metrics']['accuracy']:.1f}%")
        
        self.model_results = model_results
        return model_results
    
    def calculate_forecast_accuracy(self, y_true: np.ndarray, y_pred: np.ndarray) -> Dict[str, float]:
        """Calculate forecast-specific accuracy metrics."""
        
        # Mean Absolute Percentage Error
        mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100
        
        # Symmetric Mean Absolute Percentage Error
        smape = np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred))) * 100
        
        # Mean Absolute Scaled Error (simplified)
        mae = np.mean(np.abs(y_true - y_pred))
        naive_mae = np.mean(np.abs(np.diff(y_true)))  # Naive forecast (yesterday's value)
        mase = mae / naive_mae if naive_mae > 0 else np.inf
        
        # Forecast accuracy (100% - MAPE)
        accuracy = max(0, 100 - mape)
        
        # Directional accuracy (% of correct trend predictions)
        if len(y_true) > 1:
            true_direction = np.sign(np.diff(y_true))
            pred_direction = np.sign(np.diff(y_pred))
            directional_accuracy = np.mean(true_direction == pred_direction) * 100
        else:
            directional_accuracy = 50  # Default for single prediction
        
        return {
            'mape': mape,
            'smape': smape,
            'mase': mase,
            'accuracy': accuracy,
            'directional_accuracy': directional_accuracy
        }
    
    def generate_future_forecasts(self, horizon: int = None) -> Dict[str, Any]:
        """Generate forecasts for future periods."""
        
        horizon = horizon or self.config['forecast_horizon']
        print(f"\nüîÆ Generating {horizon}-day forecast...")
        
        # Use the latest features as base for forecasting
        latest_features = self.ts_features.iloc[-1:].copy()
        
        forecasts = []
        forecast_dates = []
        
        # Generate forecasts iteratively
        for i in range(horizon):
            # Create future date
            last_date = pd.to_datetime(latest_features['date'].iloc[0])
            future_date = last_date + timedelta(days=i+1)
            forecast_dates.append(future_date)
            
            # Update calendar features for future date
            future_features = latest_features.copy()
            future_features['day_of_week'] = future_date.weekday()
            future_features['month'] = future_date.month
            future_features['quarter'] = (future_date.month - 1) // 3 + 1
            future_features['is_weekend'] = int(future_date.weekday() >= 5)
            future_features['day_of_year'] = future_date.dayofyear
            future_features['week_of_year'] = future_date.isocalendar()[1]
            
            # Update cyclical encodings
            future_features['day_of_week_sin'] = np.sin(2 * np.pi * future_features['day_of_week'] / 7)
            future_features['day_of_week_cos'] = np.cos(2 * np.pi * future_features['day_of_week'] / 7)
            future_features['month_sin'] = np.sin(2 * np.pi * future_features['month'] / 12)
            future_features['month_cos'] = np.cos(2 * np.pi * future_features['month'] / 12)
            
            # Assume future external factors (in practice, these might be forecasted separately)
            future_features['is_holiday'] = 0  # Assume no holidays for simplicity
            future_features['promotion'] = 0   # Assume no promotions
            future_features['temperature'] = latest_features['temperature']  # Assume same temperature
            
            # Prepare features for prediction (exclude date and sales columns)
            feature_cols = [col for col in future_features.columns if col not in ['date', 'sales']]
            X_future = future_features[feature_cols]
            
            # Make prediction
            prediction = self.best_model.predict(X_future)[0]
            forecasts.append(prediction)
            
            # Update features for next iteration (simplified approach)
            # In practice, you'd update lag features with new predictions
            latest_features = future_features.copy()
        
        # Calculate prediction intervals (simplified)
        test_residuals = (self.data_splits['test'][1] - 
                         self.model_results[self.best_model_name]['predictions']['test'])
        residual_std = np.std(test_residuals)
        
        # 95% confidence intervals
        lower_bound = np.array(forecasts) - 1.96 * residual_std
        upper_bound = np.array(forecasts) + 1.96 * residual_std
        
        forecast_results = {
            'dates': forecast_dates,
            'forecasts': forecasts,
            'lower_bound': lower_bound,
            'upper_bound': upper_bound,
            'horizon': horizon,
            'model_used': self.best_model_name
        }
        
        print(f"   Generated forecasts for {horizon} days")
        print(f"   Average daily forecast: ${np.mean(forecasts):,.2f}")
        print(f"   Total forecast period revenue: ${np.sum(forecasts):,.2f}")
        print(f"   Forecast range: ${min(forecasts):,.2f} - ${max(forecasts):,.2f}")
        
        self.future_forecasts = forecast_results
        return forecast_results
    
    def create_forecasting_dashboard(self, save_plots: bool = True) -> None:
        """Create comprehensive forecasting dashboard."""
        
        print("\nüìä Creating forecasting dashboard...")
        
        # Prepare historical data for visualization
        X_test, y_test = self.data_splits['test']
        test_dates = self.ts_features.iloc[-len(y_test):]['date'].values
        test_predictions = self.model_results[self.best_model_name]['predictions']['test']
        
        # Combine historical and forecast data for visualization
        viz_data = {
            'time_series': {
                'dates': np.concatenate([test_dates, self.future_forecasts['dates']]),
                'actual': np.concatenate([y_test.values, [np.nan]*len(self.future_forecasts['forecasts'])]),
                'predicted': np.concatenate([test_predictions, self.future_forecasts['forecasts']]),
                'lower_bound': np.concatenate([test_predictions - 50, self.future_forecasts['lower_bound']]),
                'upper_bound': np.concatenate([test_predictions + 50, self.future_forecasts['upper_bound']])
            },
            'accuracy_metrics': self.model_results[self.best_model_name]['forecast_metrics'],
            'seasonal_decomposition': self.seasonal_components,
            'revenue_impact': {
                'Current': np.sum(y_test),
                'Forecast': np.sum(self.future_forecasts['forecasts']),
                'Lower Bound': np.sum(self.future_forecasts['lower_bound']),
                'Upper Bound': np.sum(self.future_forecasts['upper_bound'])
            }
        }
        
        # Create dashboard
        fig = self.visualizer.plot_sales_forecast_dashboard(
            viz_data,
            save_path='sales_forecast_dashboard.png' if save_plots else None
        )
        
        plt.show()
        
        print("‚úÖ Forecasting dashboard created")
    
    def run_complete_analysis(self) -> Dict[str, Any]:
        """Execute complete sales forecasting analysis."""
        
        print("üöÄ Starting Sales Forecasting Analysis")
        print("=" * 45)
        
        # 1. Load and analyze data
        X, y = self.load_and_analyze_sales_data()
        
        # 2. Feature engineering
        X_processed, y_processed = self.engineer_forecasting_features(X, y)
        
        # 3. Create time series splits
        splits = self.create_time_series_splits(X_processed, y_processed)
        
        # 4. Train models
        model_results = self.train_forecasting_models(splits)
        
        # 5. Generate future forecasts
        future_forecasts = self.generate_future_forecasts()
        
        # 6. Create dashboard
        self.create_forecasting_dashboard()
        
        # 7. Compile final results
        final_results = {
            'best_model': self.best_model_name,
            'model_performance': self.model_results[self.best_model_name]['test_performance'],
            'forecast_accuracy': self.model_results[self.best_model_name]['forecast_metrics'],
            'business_impact': self.model_results[self.best_model_name]['business_impact'],
            'future_forecasts': future_forecasts,
            'seasonal_patterns': self.seasonal_components,
            'data_summary': {
                'total_periods': len(X),
                'average_daily_sales': float(y.mean()),
                'sales_volatility': float(y.std()),
                'features_count': len(X_processed.columns)
            }
        }
        
        print("\nüéâ Sales Forecasting Analysis Complete!")
        print(f"   Best Model: {self.best_model_name}")
        print(f"   Forecast Accuracy: {final_results['forecast_accuracy']['accuracy']:.1f}%")
        print(f"   Test RMSE: ${final_results['model_performance']['rmse']:,.2f}")
        print(f"   Next {self.config['forecast_horizon']} days forecast: ${sum(future_forecasts['forecasts']):,.2f}")
        
        return final_results

def main():
    """Main execution function for standalone running."""
    
    # Configuration for sales forecasting
    config = {
        'data_periods': 730,
        'forecast_horizon': 30,
        'algorithms': ['linear_regression', 'random_forest', 'gradient_boosting'],
        'business_params': {
            'inventory_cost_per_unit': 10,
            'stockout_cost_per_unit': 50,
            'holding_cost_rate': 0.02
        }
    }
    
    # Run sales forecasting analysis
    forecasting_system = SalesForecastingSystem(config)
    results = forecasting_system.run_complete_analysis()
    
    return results

if __name__ == "__main__":
    results = main()